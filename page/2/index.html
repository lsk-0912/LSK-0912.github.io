<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 8.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"aurora-lsk.asia","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="选择有时候比努力更重要，但是你不努力，选择就只是空谈">
<meta property="og:type" content="website">
<meta property="og:title" content="坤博客">
<meta property="og:url" content="https://aurora-lsk.asia/page/2/index.html">
<meta property="og:site_name" content="坤博客">
<meta property="og:description" content="选择有时候比努力更重要，但是你不努力，选择就只是空谈">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="坤">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://aurora-lsk.asia/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>坤博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">坤博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://aurora-lsk.asia/2025/10/15/Scrapy%E6%A1%86%E6%9E%B6%E4%B9%8B%E5%85%A8%E7%AB%99%E7%88%AC%E5%8F%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="坤">
      <meta itemprop="description" content="选择有时候比努力更重要，但是你不努力，选择就只是空谈">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="坤博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/10/15/Scrapy%E6%A1%86%E6%9E%B6%E4%B9%8B%E5%85%A8%E7%AB%99%E7%88%AC%E5%8F%96/" class="post-title-link" itemprop="url">Scrapy框架之全站爬取</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-10-15 11:34:56 / 修改时间：16:15:50" itemprop="dateCreated datePublished" datetime="2025-10-15T11:34:56+08:00">2025-10-15</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Blog/" itemprop="url" rel="index"><span itemprop="name">Blog</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1>Scrapy框架之全站爬取</h1>
<h2 id="【一】全站爬取">【一】全站爬取</h2>
<h3 id="【1】介绍">【1】介绍</h3>
<ul>
<li>CrawlSpider：全站数据爬虫的方式，它是一个类，属于Spider的子类</li>
<li>如果不使用CrawlSpider,那么就相当于基于spider，手动发起请求，不方便</li>
<li>基于CrawlSpider可以方便地进行全站数据爬取</li>
</ul>
<h3 id="【2】CrawlSpider">【2】CrawlSpider</h3>
<h4 id="（1）创建一个工程">（1）创建一个工程</h4>
```shell
scrapy startproject ProjectName
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#### （2）创建爬虫文件</span><br><span class="line"></span><br><span class="line">- cd 切换到爬虫工程中后</span><br><span class="line">- 创建爬虫文件：</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```shell</span><br><span class="line">scrapy genspider -t crawl 爬虫文件名 www.爬虫文件名.com</span><br></pre></td></tr></table></figure>

<h4 id="（3）规则解析器">（3）规则解析器</h4>
<ul>
<li>使用CrawlSpider和spider产生的爬虫文件除了继承类不一样外还有rules的规则器</li>
</ul>
```python
rules = (
    Rule(LinkExtractor(allow=r'Items/'), callback='parse_item', follow=True),
)
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">- 在rules规则解析器内有一个链接提取器LinkExtractor(allow=r&#x27;Items/&#x27;)，callback是规则解析器指定的解析方法，follow是指爬取页面内可见部分页面还是全部</span><br><span class="line"></span><br><span class="line">- 链接提取器的作用：根据指定的规则allow=r&#x27;items/&#x27;进行指定的链接提取</span><br><span class="line"></span><br><span class="line">- 规则解析器作用：把链接提取器提取到的链接进行指定规则callback=&#x27;parse_item&#x27;的解析操作</span><br><span class="line">- follow作用：True可以把 链接提取器 继续作用到 链接提取器提取到的链接所对应的 页面 中，False爬取页面内可见部分页面</span><br><span class="line"></span><br><span class="line">## 【二】需求需要</span><br><span class="line"></span><br><span class="line">- 继续爬取下一页</span><br><span class="line">- 爬取文章详情</span><br><span class="line"></span><br><span class="line">## 【三】思路分析</span><br><span class="line"></span><br><span class="line">### 【1】Request创建</span><br><span class="line"></span><br><span class="line">- Request创建：在parse中，for循环中，创建Request对象时，传入meta</span><br><span class="line">- item对象一定要在for循环中创建，否则，当前页面都用同一个item导致同一页数据都一样</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```python</span><br><span class="line">yield Request(</span><br><span class="line">                url=article_link,</span><br><span class="line">                callback=self.detail_parse,</span><br><span class="line">                meta=&#123;&quot;item&quot;: item&#125;</span><br><span class="line">            )</span><br></pre></td></tr></table></figure>

<h3 id="【2】Response对象">【2】Response对象</h3>
<ul>
<li>Response对象：detail_parse中，通过response取出meta取出item，把文章详情写入</li>
</ul>
```python
    def detail_parse(self, response):
        # 获取到传入的item对象
        item = response.meta.get('item')
        # 解析文章详情
        content = str(response.xpath('//*[@id="topics"]').extract_first())
        # 继续向 item 对象中添加文章详情内容
        item['article_content'] = content
        # 将完整的信息返回
        yield item
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 【四】完整的思路</span><br><span class="line"></span><br><span class="line">- 爬取博客园的全部文章,并保存到数据库</span><br><span class="line"></span><br><span class="line">spiders/bokeyuan.py</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```python</span><br><span class="line">from SpiderNews.items import BoKeYuanItem</span><br><span class="line">import scrapy</span><br><span class="line">from scrapy import Request</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class BokeYuanSpider(scrapy.Spider):</span><br><span class="line">    # 爬虫文件的唯一标识</span><br><span class="line">    name = &quot;bokeyuan&quot;</span><br><span class="line">    # 允许访问的域名</span><br><span class="line">    # https://www.cnblogs.com/</span><br><span class="line">    allowed_domains = [&quot;www.cnblogs.com&quot;]</span><br><span class="line">    # 起始的url列表（很重要）</span><br><span class="line">    # 列表内部的url都会被框架进行异步请求发送</span><br><span class="line">    start_urls = [&quot;https://www.cnblogs.com/&quot;]</span><br><span class="line"></span><br><span class="line">    # 数据解析主函数：自动调用</span><br><span class="line">    # 调用的次数取决于start_urls列表内元素的个数</span><br><span class="line">    def parse(self, response):</span><br><span class="line">        # 用Xpath语法爬取数据</span><br><span class="line">        article_list = response.xpath(&#x27;//*[@id=&quot;post_list&quot;]/article&#x27;)</span><br><span class="line">        # print(article_list)</span><br><span class="line">        for article in article_list:</span><br><span class="line">            # 创建一个管道类对象</span><br><span class="line">            item = BoKeYuanItem()</span><br><span class="line">            # 拿到头像</span><br><span class="line">            # //*[@id=&quot;post_list&quot;]/article[1]/section/div/p/a/img</span><br><span class="line">            head_img_url = article.xpath(&#x27;./section/div/p/a[1]/img/@src&#x27;).extract_first()</span><br><span class="line">            # 文章的作者</span><br><span class="line">            # //*[@id=&quot;post_list&quot;]/article[1]/section/footer/a[1]/span</span><br><span class="line">            article_author = article.xpath(&#x27;./section/footer/a[1]/span/text()&#x27;).extract_first()</span><br><span class="line">            # 文章标题</span><br><span class="line">            # //*[@id=&quot;post_list&quot;]/article[1]/section/div/a</span><br><span class="line">            article_title = article.xpath(&#x27;./section/div/a/text()&#x27;).extract_first().strip()</span><br><span class="line">            # 创建一个详情链接</span><br><span class="line">            # //*[@id=&quot;post_list&quot;]/article[1]/section/div/a</span><br><span class="line">            article_link = article.xpath(&#x27;./section/div/a/@href&#x27;).extract_first()</span><br><span class="line">            # 拿到文章内容</span><br><span class="line">            # //*[@id=&quot;post_list&quot;]/article[2]/section/div/p/text()</span><br><span class="line">            #//*[@id=&quot;post_list&quot;]/article[1]/section/div/p/text()</span><br><span class="line">            # /html/body/div/div[3]/div/div[2]/div[1]/div[4]/article[3]/section/div/p/text()</span><br><span class="line">            article_desc_list = article.xpath(&#x27;./section/div/p/text()&#x27;).extract()</span><br><span class="line">            article_desc = &#x27;&#x27;</span><br><span class="line">            for article_desc in article_desc_list:</span><br><span class="line">                if not article_desc:</span><br><span class="line">                    pass</span><br><span class="line">                else:</span><br><span class="line">                    article_desc = article_desc.strip()</span><br><span class="line">            # 文章更新时间</span><br><span class="line">            # //*[@id=&quot;post_list&quot;]/article[1]/section/footer/span[1]/span</span><br><span class="line">            article_update_time = article.xpath(&#x27;./section/footer/span[1]/span/text()&#x27;).extract_first().strip()</span><br><span class="line">            # print(article_update_time)</span><br><span class="line">            # itme是一个字典--&gt;用字典方便，可以update()更新数据，更新的时候，更新字段要和管道类里面的字段一摸一样</span><br><span class="line">            # print(f&quot;----&#123;article_desc&#125;---&quot;)</span><br><span class="line">            item.update(&#123;</span><br><span class="line">                &quot;head_img_url&quot;: head_img_url,</span><br><span class="line">                &quot;article_author&quot;: article_author,</span><br><span class="line">                &quot;article_title&quot;: article_title,</span><br><span class="line">                &quot;article_link&quot;:article_link,</span><br><span class="line">                &quot;article_desc&quot;: article_desc,</span><br><span class="line">                &quot;article_update_time&quot;: article_update_time</span><br><span class="line">            &#125;)</span><br><span class="line">            # 将itme对象返回出去</span><br><span class="line">            # return 会结束整个程序，不用它</span><br><span class="line">            # 我们用yield，yield可以保存item的状态，不会终止程序的执行</span><br><span class="line">            yield Request(</span><br><span class="line">                url=article_link,</span><br><span class="line">                callback=self.detail_parse,</span><br><span class="line">                meta=&#123;&quot;item&quot;: item&#125;</span><br><span class="line">            )</span><br><span class="line">        # 获取下一页的链接地址</span><br><span class="line">        # //*[@id=&quot;paging_block&quot;]/div/a[5]</span><br><span class="line">        next_url = &#x27;https://www.cnblogs.com&#x27; + response.xpath(&#x27;//*[@id=&quot;paging_block&quot;]/div/a[last()]/@href&#x27;).extract_first()</span><br><span class="line">        yield Request(</span><br><span class="line">            url=next_url,</span><br><span class="line">            callback=self.parse</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def detail_parse(self, response):</span><br><span class="line">        # 获取到传入的item对象</span><br><span class="line">        item = response.meta.get(&#x27;item&#x27;)</span><br><span class="line">        # 解析文章详情</span><br><span class="line">        content = str(response.xpath(&#x27;//*[@id=&quot;topics&quot;]&#x27;).extract_first())</span><br><span class="line">        # 继续向 item 对象中添加文章详情内容</span><br><span class="line">        item[&#x27;article_content&#x27;] = content</span><br><span class="line">        # 将完整的信息返回</span><br><span class="line">        yield item</span><br></pre></td></tr></table></figure>

<ul>
<li>创建数据库，和字段</li>
<li>然后再items.py中创建管道类和管道字段</li>
</ul>
<p><a target="_blank" rel="noopener" href="http://items.py">items.py</a></p>
```python
import scrapy

# 创建管道类
# 就像你再django中创建的模型表
class BoKeYuanItem(scrapy.Item):
    # 就像你模型表的字段
    head_img_url = scrapy.Field()
    article_author = scrapy.Field()
    article_title = scrapy.Field()
    article_link = scrapy.Field()
    article_desc = scrapy.Field()
    article_content = scrapy.Field()
    article_update_time = scrapy.Field()

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pipelines.py</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```python</span><br><span class="line">import pymysql</span><br><span class="line"></span><br><span class="line"># useful for handling different item types with a single interface</span><br><span class="line">from itemadapter import ItemAdapter</span><br><span class="line">from pymysql.cursors import DictCursor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 这里处理函数</span><br><span class="line"></span><br><span class="line">class SpidernewsPipeline:</span><br><span class="line">    def process_item(self, item, spider):</span><br><span class="line">        return item</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class BoKeYuanPipeline:</span><br><span class="line">    # 爬虫程序开始时走的</span><br><span class="line">    def open_spider(self, spider):</span><br><span class="line">        # 可以做数据库的初始操作</span><br><span class="line">        print(&quot;爬虫开始撒！！初始化数据库连接&quot;)</span><br><span class="line">        # 连接数据库</span><br><span class="line">        self.conn = pymysql.connect(</span><br><span class="line">            user=&quot;root&quot;,</span><br><span class="line">            password=&quot;1234567&quot;,</span><br><span class="line">            host=&quot;127.0.0.1&quot;,</span><br><span class="line">            port=3306,</span><br><span class="line">            database=&quot;article_scrapy&quot;,</span><br><span class="line">            charset=&quot;utf8mb4&quot;,</span><br><span class="line">            cursorclass=DictCursor,</span><br><span class="line"></span><br><span class="line">        )</span><br><span class="line">        # 创建一个cursor对象</span><br><span class="line">        self.cursor = self.conn.cursor()</span><br><span class="line">        print(&quot;爬虫开始撒！！初始化数据库连接成功&quot;)</span><br><span class="line"></span><br><span class="line">    def process_item(self, item, spider):</span><br><span class="line">        # print(item)</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        :param item: 就是你的创建的每个管道字段</span><br><span class="line">        :param spider:</span><br><span class="line">        :return:</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 获取数据</span><br><span class="line">        head_img_url = item.get(&quot;head_img_url&quot;)</span><br><span class="line">        article_author = item.get(&quot;article_author&quot;)</span><br><span class="line">        article_title = item.get(&quot;article_title&quot;)</span><br><span class="line">        article_link = item.get(&quot;article_link&quot;)</span><br><span class="line">        article_desc = item.get(&quot;article_desc&quot;)</span><br><span class="line">        article_content = item.get(&quot;article_content&quot;)</span><br><span class="line">        article_update_time = item.get(&quot;article_update_time&quot;)</span><br><span class="line"></span><br><span class="line">        # 向数据库插入数据</span><br><span class="line">        sql = &#x27;insert into article(head_img_url,article_author,article_title,article_link,article_desc, article_content,article_update_time) values(%s,%s,%s,%s,%s,%s,%s)&#x27;</span><br><span class="line"></span><br><span class="line">        # 执行spl语句</span><br><span class="line">        self.cursor.execute(sql, [head_img_url, article_author, article_title, article_link, article_desc, article_content, article_update_time])</span><br><span class="line">        # 提交事务</span><br><span class="line">        self.conn.commit()</span><br><span class="line">        print(f&quot;当前作者--&#123;article_author&#125;--插入成功&quot;)</span><br><span class="line">        # print(item)</span><br><span class="line">        # 注意每次用完item记得返回出去，不然会报错</span><br><span class="line">        return item</span><br><span class="line"></span><br><span class="line">    # 爬虫程序结束时走的</span><br><span class="line">    def close_spider(self, spider):</span><br><span class="line">        # 可以将数据库，连接关闭</span><br><span class="line">        print(&quot;爬虫结束！！！关闭数据库&quot;)</span><br><span class="line">        # 关闭对象</span><br><span class="line">        self.conn.close()</span><br><span class="line">        # 关闭连接对象</span><br><span class="line">        self.cursor.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="http://settings.py">settings.py</a></p>
<ul>
<li>要将你新创建的类，再配置中注册</li>
</ul>
```python
# 管道类
ITEM_PIPELINES = {
    # 项目默认的处理类，没有任何操作
   "SpiderNews.pipelines.SpidernewsPipeline": 300,
    # 自己写的注册的处理类，后面你的数字越小优先级越高，根据优先级一次执行管道处理类
   "SpiderNews.pipelines.BoKeYuanPipeline": 300,
}
```


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://aurora-lsk.asia/2025/10/15/Scrapy%E6%A1%86%E6%9E%B6%E4%B9%8B%E4%B8%AD%E9%97%B4%E4%BB%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="坤">
      <meta itemprop="description" content="选择有时候比努力更重要，但是你不努力，选择就只是空谈">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="坤博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/10/15/Scrapy%E6%A1%86%E6%9E%B6%E4%B9%8B%E4%B8%AD%E9%97%B4%E4%BB%B6/" class="post-title-link" itemprop="url">Scrapy框架之中间件</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-10-15 11:34:56 / 修改时间：16:15:50" itemprop="dateCreated datePublished" datetime="2025-10-15T11:34:56+08:00">2025-10-15</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Blog/" itemprop="url" rel="index"><span itemprop="name">Blog</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1>Scrapy框架之中间件</h1>
<h2 id="【一】爬虫中间件">【一】爬虫中间件</h2>
```python
from scrapy import signals

class SpiderNewsSpiderMiddleware:
	
    # 如果有某一个函数没有被重写，那就使用默认的函数对象
    
    @classmethod
    # 是一个类方法，它会在创建爬虫实例时被Scrapy调用，用于初始化爬虫中间件的实例
    def from_crawler(cls, crawler):
        # 该方法是scrapy用于创建爬虫示例的方法
        # 首先创建一个中间价实例  s
        s = cls()
        # 通过crawler.signals.connect方法连接了，spider_opened(爬虫打开)信号和对应的处理方法
        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)
        return s
	
    # process_spider_input 方法会在响应从爬虫中间件传递到爬虫之前调用
    # 可以用来对响应进行预处理或检查
    def process_spider_input(self, response, spider):
        """
        :param response: 响应对象
        :param spider: 当前的爬虫实例
        :return:
        """
        # 当响应从爬虫中间件进入爬虫时，调用该方法进行处理
        # 应返回None或引发异常
        return None
	
    # process_spider_output 方法在爬虫处理完响应后会被调用
    # 主要用于对爬虫处理结果进行进一步处理或过滤，并将处理结果返回
    # 必须返回一个可迭代的Request对象或item对象
    def process_spider_output(self, response, result, spider):
        """
        :param response: 是爬虫处理后的响应对象
        :param result: 是爬虫的处理结果
        :param spider: 是当前爬虫实例
        :return:
        """
        # 当爬虫处理完响应后，调用该方法对数据进行处理
        # 必须返回一个request对象或item对象
        for i in result:
            yield i
	
    # process_spider_exception 方法在爬虫或 process_spider_input() 方法中抛出异常时会被调用
    # 这个方法可以用来对爬虫处理过程中的异常进行处理
    # 可以返回 None 或一个可迭代的Request对象或item对象
    def process_spider_exception(self, response, exception, spider):
        """
        :param response: 发生异常的响应体
        :param exception: 是抛出的异常对象
        :param spider: 是当前的爬虫实例
        :return:
        """
        # 当爬虫中抛出异常时，调用该方法进行处理
        # 应返回None或者一个可迭代的Request对象或item对象
        pass
	
    # process_start_requests 方法在爬虫启动时被调用
    # 用于对初始请求进行处理
    def process_start_requests(self, start_requests, spider):
        """
        :param start_requests: 是初始请求的列表
        :param spider: 当前爬虫的实例
        :return:
        """
        # 在爬虫启动时，对初始请求进行处理
        for r in start_requests:
            yield r
	
    # 在爬虫打开时被调用
    # 在这个方法中，通过日志记录器(logger)输出 "Spider opened: 爬虫名称" 的信息
    def spider_opened(self, spider):
        """
        :param spider: 当前爬虫的实例
        :return:
        """
        spider.logger.info("Spider opened: %s" % spider.name)
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 【二】下载中间件</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```python</span><br><span class="line">from scrapy import signals</span><br><span class="line"></span><br><span class="line">class SpidernewsDownloaderMiddleware:</span><br><span class="line"></span><br><span class="line">    @classmethod</span><br><span class="line">    def from_crawler(cls, crawler):</span><br><span class="line">        # Scrapy使用该方法创建我们的爬虫</span><br><span class="line">        s = cls()</span><br><span class="line">        # 通过signals连接spider_opened信号和spider_opened方法</span><br><span class="line">        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)</span><br><span class="line">        return s</span><br><span class="line"></span><br><span class="line">    # 拦截请求的所有对象</span><br><span class="line">    # 参数：request就是拦截到的请求对象，spider爬虫文件中爬虫类实例化的对象</span><br><span class="line">    # spider参数的作用可以实现类和中间类的数据交互</span><br><span class="line">    def process_request(self, request, spider):</span><br><span class="line">        # 返回None：继续处理本次请求，执行下一个中间件的process_request方法</span><br><span class="line">        # 返回一个Response对象：执行当前中间件的process_response方法，重新回到引擎，被调度</span><br><span class="line">        # 返回一个Request对象：直接返回给引擎，被调度。进入调度器等待下次被调用</span><br><span class="line">        # 抛出IgnoreRequest异常：调用已安装的下载中间件的process_exception方法</span><br><span class="line">        return None</span><br><span class="line"></span><br><span class="line">    # 拦截处理所有的响应对象</span><br><span class="line">    # 参数response就是拦截到的响应体对象，request就是被拦截到响应对象对应的唯一的一个请求对象</span><br><span class="line">    def process_response(self, request, response, spider):</span><br><span class="line">        # 返回一个Response对象：继续执行，引入引擎，被调度到爬虫中进行解析</span><br><span class="line">        # 返回一个Request对象：进入引擎，返回到调度器被重新调用</span><br><span class="line">        # 或者抛出IgnoreRequest异常：抛出异常</span><br><span class="line">        return response</span><br><span class="line"></span><br><span class="line">    # 拦截和处理发生异常的请求对象</span><br><span class="line">    # 参数：reqeust就是拦截到的发生异常的请求对象</span><br><span class="line">    # 方法存在的意义：将发生异常的请求拦截到，然后对其进行修正</span><br><span class="line">    def process_exception(self, request, exception, spider):</span><br><span class="line">        # 当下载处理程序或process_request()方法（来自其他下载中间件）引发异常时调用。</span><br><span class="line"></span><br><span class="line">        # 必须返回以下之一：</span><br><span class="line">        # 返回None：继续处理该异常</span><br><span class="line">        # 返回一个Response对象：停止process_exception()链</span><br><span class="line">        # 返回一个Request对象：停止process_exception()链</span><br><span class="line">        pass</span><br><span class="line"></span><br><span class="line">    #  控制日志数据的（忽略）</span><br><span class="line">    def spider_opened(self, spider):</span><br><span class="line">        spider.logger.info(&quot;Spider opened: %s&quot; % spider.name)</span><br></pre></td></tr></table></figure>

<ul>
<li>from_crawler(cls, crawler)方法：该方法是Scrapy用来创建爬虫的入口点。它返回一个中间件对象，并通过crawler.signals连接到spider_opened信号，以便在爬虫开启时执行相应的操作。</li>
<li>process_request(self, request, spider)方法：该方法在发送请求之前被调用。您可以在此方法中对请求进行处理和修改。返回值决定了后续处理的行为，可以是None继续处理当前请求，返回一个Response对象以便执行process_response方法，返回一个Request对象以便重新调度，或者抛出IgnoreRequest异常以调用其他下载中间件的process_exception方法。</li>
<li>process_response(self, request, response, spider)方法：该方法在收到响应后被调用。您可以在此方法中对响应进行处理和修改。返回值决定了后续处理的行为，可以是返回Response对象以便进一步处理和解析，返回Request对象以便重新调度，或者抛出IgnoreRequest异常。</li>
<li>process_exception(self, request, exception, spider)方法：当下载处理程序或其他下载中间件的process_request方法引发异常时调用该方法。您可以在此处处理异常，并根据需要返回值。</li>
<li>spider_opened(self, spider)方法：在爬虫开启时被调用。在这个示例中，它会输出一个日志信息。</li>
</ul>
<h2 id="【三】配置文件">【三】配置文件</h2>
```python
# 是否启用爬虫中间件
SPIDER_MIDDLEWARES = {
   "SpiderNews.middlewares.SpiderNewsSpiderMiddleware": 543,
}

# 是否启用下载器中间件
DOWNLOADER_MIDDLEWARES = {
   "SpiderNews.middlewares.SpiderNewsDownloaderMiddleware": 543,
}
```


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://aurora-lsk.asia/2025/10/15/Scrapy%E6%A1%86%E6%9E%B6%E4%B9%8B%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%BB%8B%E7%BB%8D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="坤">
      <meta itemprop="description" content="选择有时候比努力更重要，但是你不努力，选择就只是空谈">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="坤博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/10/15/Scrapy%E6%A1%86%E6%9E%B6%E4%B9%8B%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%BB%8B%E7%BB%8D/" class="post-title-link" itemprop="url">Scrapy框架之配置文件介绍</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-10-15 11:34:56 / 修改时间：16:15:50" itemprop="dateCreated datePublished" datetime="2025-10-15T11:34:56+08:00">2025-10-15</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Blog/" itemprop="url" rel="index"><span itemprop="name">Blog</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1>Scrapy框架之配置文件介绍</h1>
```python

from fake_useragent import UserAgent

# 当前项目的项目名字
BOT_NAME = "SpiderNews"

# 当前爬虫项目所在的位置
SPIDER_MODULES = ["SpiderNews.spiders"]
# 当前爬虫项目所在的位置
NEWSPIDER_MODULE = "SpiderNews.spiders"

# 指定那个日志级别，达到了你设置的日志级别才会显示日志
# 指定输出日志的类型：
LOG_LEVEL = "WARNING"

# 自定义请求头
# 我们也可以写成：
USER_AGENT = UserAgent().random
#USER_AGENT = "SpiderNews (+http://www.yourdomain.com)"

# Obey robots.txt rules
# 是否遵循robots.txt协议
ROBOTSTXT_OBEY = False

# 最大请求数量
#CONCURRENT_REQUESTS = 32


# 下载延迟，如果下载三秒中还没反应，会直接抛出异常
#DOWNLOAD_DELAY = 3

# 并发请求的最大数量
#CONCURRENT_REQUESTS_PER_DOMAIN = 16
# 并发请求的ip最大数量
#CONCURRENT_REQUESTS_PER_IP = 16

# 是否启用cookie
#COOKIES_ENABLED = False

# 禁用控制台输出
#TELNETCONSOLE_ENABLED = False

# 默认的请求头参数
#DEFAULT_REQUEST_HEADERS = {
#    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
#    "Accept-Language": "en",
#}

# 是否启用爬虫中间件
#SPIDER_MIDDLEWARES = {
#    "SpiderNews.middlewares.SpidernewsSpiderMiddleware": 543,
#}

# 是否启用下载器中间件
#DOWNLOADER_MIDDLEWARES = {
#    "SpiderNews.middlewares.SpidernewsDownloaderMiddleware": 543,
#}

# 调度引擎
#EXTENSIONS = {
#    "scrapy.extensions.telnet.TelnetConsole": None,
#}

# 管道类
ITEM_PIPELINES = {
    # 项目默认的处理类，没有任何操作
   "SpiderNews.pipelines.SpidernewsPipeline": 300,
    # 自己写的注册的处理类，后面你的数字越小优先级越高，根据优先级一次执行管道处理类
   "SpiderNews.pipelines.BoKeYuanPipeline": 300,
}

# 自动限速
#AUTOTHROTTLE_ENABLED = True
# 下载延迟
#AUTOTHROTTLE_START_DELAY = 5
# 最大并发数延迟
#AUTOTHROTTLE_MAX_DELAY = 60
# The average number of requests Scrapy should be sending in parallel to
# each remote server
#AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0
# Enable showing throttling stats for every response received:
#AUTOTHROTTLE_DEBUG = False

# Enable and configure HTTP caching (disabled by default)
# See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings
#HTTPCACHE_ENABLED = True
#HTTPCACHE_EXPIRATION_SECS = 0
#HTTPCACHE_DIR = "httpcache"
#HTTPCACHE_IGNORE_HTTP_CODES = []
#HTTPCACHE_STORAGE = "scrapy.extensions.httpcache.FilesystemCacheStorage"

# Set settings whose default value is deprecated to a future-proof value
REQUEST_FINGERPRINTER_IMPLEMENTATION = "2.7"
TWISTED_REACTOR = "twisted.internet.asyncioreactor.AsyncioSelectorReactor"
FEED_EXPORT_ENCODING = "utf-8"

```


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://aurora-lsk.asia/2025/10/15/Scrapy%E6%A1%86%E6%9E%B6%E4%B9%8B%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="坤">
      <meta itemprop="description" content="选择有时候比努力更重要，但是你不努力，选择就只是空谈">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="坤博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/10/15/Scrapy%E6%A1%86%E6%9E%B6%E4%B9%8B%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/" class="post-title-link" itemprop="url">Scrapy框架之布隆过滤器</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-10-15 11:34:56 / 修改时间：16:15:50" itemprop="dateCreated datePublished" datetime="2025-10-15T11:34:56+08:00">2025-10-15</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Blog/" itemprop="url" rel="index"><span itemprop="name">Blog</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1>Scrapy框架之布隆过滤器</h1>
<h2 id="【一】布隆过滤器介绍">【一】布隆过滤器介绍</h2>
<ul>
<li>布隆过滤器是一种基于哈希函数映射的数据结构，常用于快速判断一个元素是否在一个集合内，具有较好的时间和空间效率</li>
</ul>
<h2 id="【二】python中使用布隆过滤器">【二】python中使用布隆过滤器</h2>
<h3 id="【1】安装模块">【1】安装模块</h3>
```shell
pip install pybloom_live
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 【2】测试布隆过滤器</span><br><span class="line"></span><br><span class="line">- 我们可以自己扩展错误率，底层数组如果大于了错误率会自动扩容</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```python</span><br><span class="line"># 设置了错误率，就会自动扩容</span><br><span class="line"># 不设置错误率，不会自动扩容</span><br><span class="line"></span><br><span class="line"># 首先引入模块</span><br><span class="line">from pybloom_live import ScalableBloomFilter</span><br><span class="line"></span><br><span class="line"># 创建一个可扩容的布隆过滤器对象</span><br><span class="line"># initial_capacity：初始的过滤器对象</span><br><span class="line"># error_rate：期望的错误率</span><br><span class="line"># mode：过滤器模式，可选的值有：</span><br><span class="line"># ScalableBloomFilter.SMALL_SET_GROWTH：很慢但是占用更少的内存空间</span><br><span class="line"># ScalableBloomFilter.LARGE_SET_GROWTH: 很快，但是需要占用更多的内存</span><br><span class="line">bloom = ScalableBloomFilter(initial_capacity=100, error_rate=0.001, mode=ScalableBloomFilter.LARGE_SET_GROWTH)</span><br><span class="line"></span><br><span class="line"># 添加元素到布隆过滤器中</span><br><span class="line">url = &quot;www.cnblogs.com&quot;</span><br><span class="line">url2 = &quot;www.baidu.com&quot;</span><br><span class="line">bloom.add(url)</span><br><span class="line">bloom.add(url2)</span><br><span class="line"></span><br><span class="line"># 判断元素是否在布隆过滤器中</span><br><span class="line">print(url in bloom)</span><br><span class="line">print(url2 in bloom)</span><br></pre></td></tr></table></figure>

<ul>
<li>add方法：将元素添加到布隆过滤器中</li>
<li>使用in关键字段判断元素是否存在于布隆过滤器中</li>
</ul>
````python
````

<h2 id="【三】总结">【三】总结</h2>
<ul>
<li>
<p>如果有去重的情况，就可以使用集合</p>
</li>
<li>
<ul>
<li>但是集合占的内存空间大，如果到了亿级别的数据量，想一种更小内存占用，而去重的方案</li>
<li>布隆过滤器</li>
</ul>
</li>
<li>
<p>布隆过滤器：</p>
</li>
<li>
<ul>
<li>通过不同的hash函数，加底层数组实现的极小内存去重</li>
</ul>
</li>
<li>
<p>python中如何使用：pybloom_live</p>
</li>
<li>
<ul>
<li>指定错误率</li>
<li>指定大小</li>
</ul>
</li>
<li>
<p>使用redis实现布隆过滤器</p>
</li>
<li>
<ul>
<li>编译redis(把第三方扩展布隆过滤器编译进去，才有这个功能)</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://aurora-lsk.asia/2025/10/15/Scrapy%E6%A1%86%E6%9E%B6%E4%B9%8B%E8%AF%B7%E6%B1%82%E5%A4%B4%E6%93%8D%E4%BD%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="坤">
      <meta itemprop="description" content="选择有时候比努力更重要，但是你不努力，选择就只是空谈">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="坤博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/10/15/Scrapy%E6%A1%86%E6%9E%B6%E4%B9%8B%E8%AF%B7%E6%B1%82%E5%A4%B4%E6%93%8D%E4%BD%9C/" class="post-title-link" itemprop="url">Scrapy框架之请求头操作</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-10-15 11:34:56 / 修改时间：16:15:50" itemprop="dateCreated datePublished" datetime="2025-10-15T11:34:56+08:00">2025-10-15</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Blog/" itemprop="url" rel="index"><span itemprop="name">Blog</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1>Scrapy框架之请求头操作</h1>
<h2 id="【一】携带代理">【一】携带代理</h2>
<ul>
<li>再下载中间件的process_request方法中写</li>
</ul>
```python
    def process_request(self, request, spider):
        # 携带代理
        proxies = {
            'http':f'http://{"222.190.168.159"}:{"7788"}'
        }
        # 通过request的meta属性添加额外的代理ip
        request.meta['proxy'] = proxies
        print(request.meta)
        
        return None
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 【二】携带cookie</span><br><span class="line"></span><br><span class="line">- 再下载中间件的process_request方法中写</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```python</span><br><span class="line">		# 携带cookie</span><br><span class="line">        print(dir(request))  # 里面有cookie</span><br><span class="line">        # 设置进去</span><br><span class="line">        request.cookies = &#x27;cookies&#x27;</span><br></pre></td></tr></table></figure>

<h2 id="【三】向请求头中设置参数">【三】向请求头中设置参数</h2>
<ul>
<li>referer：声明来源地址</li>
</ul>
```python
		# 向请求头中设置参数
        # referer: 声明来源地址
        # 比如
        request.headers['referer'] = "https://www.baidu.com"
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 【四】随机的请求头</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```python</span><br><span class="line"># 设置随机的请求头(也可以直接再配置文件中声明：再配置文件中声明，所有的请求都是一样的)</span><br><span class="line">request.headers[&quot;User-Agent&quot;] = UserAgent().random</span><br></pre></td></tr></table></figure>

<h2 id="【五】总结">【五】总结</h2>
```python
# 拦截请求的所有对象
    # 参数：request就是拦截到的请求对象，spider爬虫文件中爬虫类实例化的对象
    # spider参数的作用可以实现类和中间类的数据交互
    def process_request(self, request, spider):
        """
        # 携带代理
        proxies = {
            'http':f'http://{"222.190.168.159"}:{"7788"}'
        }
        # 通过request的meta属性添加额外的代理ip
        request.meta['proxy'] = proxies
        print(request.meta)
        """

        # 携带cookie
        print(dir(request))  # 里面有cookie
        request.cookies = 'cookies'

        # 向请求头中设置参数
        # referer: 声明来源地址
        # 比如
        request.headers['referer'] = "https://www.baidu.com"

        # 设置随机的请求头(也可以直接再配置文件中声明：再配置文件中声明，所有的请求都是一样的)
        request.headers["User-Agent"] = UserAgent().random
        return None
```


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://aurora-lsk.asia/2025/10/15/MySQL%E8%BF%9B%E9%98%B6%E7%9F%A5%E8%AF%86/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="坤">
      <meta itemprop="description" content="选择有时候比努力更重要，但是你不努力，选择就只是空谈">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="坤博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/10/15/MySQL%E8%BF%9B%E9%98%B6%E7%9F%A5%E8%AF%86/" class="post-title-link" itemprop="url">MySQL进阶知识</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-10-15 11:34:56 / 修改时间：16:15:50" itemprop="dateCreated datePublished" datetime="2025-10-15T11:34:56+08:00">2025-10-15</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Blog/" itemprop="url" rel="index"><span itemprop="name">Blog</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1>MySQL进阶知识之视图</h1>
<h2 id="【一】视图介绍">【一】视图介绍</h2>
<h3 id="【1】什么是视图">【1】什么是视图</h3>
<ul>
<li>视图是一种查询结果的抽象表示</li>
<li>它提供了一种灵活和安全的方式来访问和操作数据库的数据</li>
<li>通过对视图的使用，用户可以根据自己的需求获取所需的数据，而无需直接访问底层的基本表</li>
</ul>
<h3 id="【2】为什么要用视图">【2】为什么要用视图</h3>
<ul>
<li>如果要频繁操作一张虚拟的表（这张表是拼表组成），就可以制作成视图，后续直接操作</li>
</ul>
<h3 id="【3】视图的优点">【3】视图的优点</h3>
<ul>
<li>简化复杂查询</li>
<li>数据安全性</li>
<li>数据完整性</li>
<li>逻辑数据独立性</li>
<li>性能优化</li>
</ul>
<h3 id="【4】总结">【4】总结</h3>
<ul>
<li>视图可以简化查询操作、保护数据安全性、实现数据安全性、提高系统的可维护性和性能优化</li>
<li>视图提供了一种灵活且安全的数据访问方式，使用视图能够根据自身需要方便地获取和操作数据</li>
</ul>
<h2 id="【二】使用视图">【二】使用视图</h2>
<h3 id="【1】语法">【1】语法</h3>
```sql
create view 视图名（表名）as 虚拟表的查询SQL语句
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 【2】创建视图</span><br><span class="line"></span><br><span class="line">- 使用视图语法创建一个视图</span><br><span class="line">- 创建视图时，需要指定视图的名称和查询的原表和过滤条件</span><br><span class="line"></span><br><span class="line">- 案例</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```sql</span><br><span class="line">create view my_course as select cname,teacher_id from course where cid=2;</span><br></pre></td></tr></table></figure>

<ul>
<li>my_course：视图名称</li>
<li><code>select cname,teacher_id from course where cid</code> ：SQL语句</li>
<li>course: 表名</li>
<li>cname,teacher_id：要选择的列</li>
<li>cid=2: 过滤条件</li>
</ul>
<p><img src="D:%5Cpycharm%5CTemporary_notes%5C%E5%9B%BE%E7%89%87%5Cimage-20240603164131332.png" alt="image-20240603164131332"></p>
<h3 id="【3】视图查询">【3】视图查询</h3>
```sql\
select * from my_course;
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">![image-20240603164139257](D:\pycharm\Temporary_notes\图片\image-20240603164139257.png)</span><br><span class="line"></span><br><span class="line">### 【4】更新视图</span><br><span class="line"></span><br><span class="line">- 更新了视图表，之前的表也会随之更新</span><br><span class="line"></span><br><span class="line">- 对视图进行操作：---》update语句</span><br><span class="line">- 只有满足一定条件的视图才支持更新操作</span><br><span class="line">- 语法</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```sql</span><br><span class="line">UPDATE my_course SET column1 = value1 WHERE condition;</span><br></pre></td></tr></table></figure>

<ul>
<li>my_course：视图名</li>
<li>column1：更新的列</li>
<li>column1：设置的值</li>
<li>condition：更新的条件</li>
</ul>
```sql
UPDATE my_course SET cname = '化学' WHERE cname='物理';
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">![image-20240603164725739](D:\pycharm\Temporary_notes\图片\image-20240603164725739.png)</span><br><span class="line"></span><br><span class="line">### 【5】删除视图</span><br><span class="line"></span><br><span class="line">- 语法</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```sql</span><br><span class="line">drop view my_course;</span><br></pre></td></tr></table></figure>

<ul>
<li>my_course : 视图名</li>
</ul>
<p><img src="D:%5Cpycharm%5CTemporary_notes%5C%E5%9B%BE%E7%89%87%5Cimage-20240603164754960.png" alt="image-20240603164754960"></p>
<h2 id="【三】总结">【三】总结</h2>
<ul>
<li>创建视图在硬盘上只会有表结构不会有表数据
<ul>
<li>表数据还是来自之前的表</li>
</ul>
</li>
<li>视图一般只会用来查询</li>
<li>当创建了较多视图后，会造成数据的难以维护</li>
</ul>
<h1>MySQL进阶知识之触发器</h1>
<h2 id="【一】触发器介绍">【一】触发器介绍</h2>
<h3 id="【1】什么是触发器">【1】什么是触发器</h3>
<ul>
<li>满足对表数据的增删改的情况下，自动触发的功能，成为触发器</li>
<li>触发器可以作为一种数据库的约束，用于保证数据的完整性和一致性。</li>
</ul>
<h3 id="【2】触发器的特点">【2】触发器的特点</h3>
<ul>
<li>触发器和表一起创建，修改，删除</li>
<li>触发器可以在特定的数据操作之前或之后触发执行</li>
<li>触发器可以根据用户定义的条件判断是否执行相应的逻辑</li>
<li>触发器可以调用储存过程、函数、触发其他触发器等，实行更复杂的业务逻辑</li>
</ul>
<h3 id="【3】为何使用触发器">【3】为何使用触发器</h3>
<ul>
<li>
<p>可以帮助我们实现日志、监控、处理等操作</p>
<ul>
<li>
<p>使用触发器可以实现很多功能</p>
</li>
<li>
<ul>
<li>比如数据验证、数据补全、数据同步、日志记录等。</li>
</ul>
</li>
<li>
<p>但需要注意，触发器的使用也需要谨慎，过多或不当的触发器可能会对数据库性能产生负面影响，因此在设计和使用触发器时应考虑到业务需求和性能方面的平衡。</p>
</li>
</ul>
</li>
</ul>
<h2 id="【二】触发器的六种使用情况">【二】触发器的六种使用情况</h2>
<ul>
<li>增前，增后，删前，删后，改前，改后</li>
</ul>
<h2 id="【三】语法结构">【三】语法结构</h2>
```sql
create trigger 触发器的名字 
before/after 
insert/update/delete 
on 
表名 
for each row begin 
SQL语句
end;
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 【四】示例</span><br><span class="line"></span><br><span class="line">### 【1】定义创建触发器（在插入数据前触发）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```sql</span><br><span class="line">CREATE TRIGGER trigger_name</span><br><span class="line">BEFORE INSERT ON table_name</span><br><span class="line">FOR EACH ROW</span><br><span class="line">BEGIN</span><br><span class="line">    -- 触发器逻辑</span><br><span class="line">END;</span><br></pre></td></tr></table></figure>

<h3 id="【2】定义绑定触发器案例（在插入数据前触发）">【2】定义绑定触发器案例（在插入数据前触发）</h3>
```sql
CREATE TRIGGER trigger_name
BEFORE INSERT ON table_name
FOR EACH ROW
BEGIN
    -- 您可以在这里执行各种操作，比如插入另一张表、更新其他表、计算值等。
    -- 下面是一个示例，将新插入的数据中的某一列设置为当前时间。
    SET NEW.column_name = NOW();
END;
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 【3】绑定触发器案例</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```sql</span><br><span class="line">-- 将名为 &quot;trigger_name&quot; 的触发器绑定到名为 &quot;table_name&quot; 的表上</span><br><span class="line">ALTER TABLE table_name</span><br><span class="line">ADD CONSTRAINT trigger_name</span><br><span class="line">AFTER INSERT ON table_name</span><br><span class="line">FOR EACH ROW</span><br><span class="line">BEGIN</span><br><span class="line">    -- 触发器逻辑</span><br><span class="line">END;</span><br></pre></td></tr></table></figure>

<h3 id="【4】在插入之前触发示例">【4】在插入之前触发示例</h3>
```sql
create trigger tri_before_insert_t1 before insert on t1
for each row
begin
	sql语句
end;
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 【5】在插入之后触发示例</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```sql</span><br><span class="line">create trigger tigger_name before insert on table_name</span><br><span class="line">for each row</span><br><span class="line">begin</span><br><span class="line">	--触发器逻辑</span><br><span class="line">end;</span><br></pre></td></tr></table></figure>

<h3 id="【6】查看当前下所有库的触发器信息">【6】查看当前下所有库的触发器信息</h3>
```sql
show triggers\G;
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 【7】删除当前库下指定的触发器信息</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```sql</span><br><span class="line">drop trigger 触发器名称;</span><br></pre></td></tr></table></figure>

<h3 id="【8】案例">【8】案例</h3>
<h4 id="（1）建表">（1）建表</h4>
```sql
CREATE TABLE cmd (
  id INT PRIMARY KEY auto_increment,
  USER CHAR (32),
  priv CHAR (10),
  cmd CHAR (64),
  sub_time datetime, #提交时间
  success enum ('yes', 'no') #0代表执行失败
);


CREATE TABLE errlog (
  id INT PRIMARY KEY auto_increment,
  err_cmd CHAR (64),
  err_time datetime
);
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">![image-20240603183928319](D:\pycharm\Temporary_notes\图片\image-20240603183928319.png)</span><br><span class="line"></span><br><span class="line">#### (2)需求</span><br><span class="line"></span><br><span class="line">&#125;cmd表插入数据的success如果值为no 则去errlog表中插入一条记录</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```sql</span><br><span class="line">delimiter $$  # 将mysql默认的结束符由;换成$$</span><br><span class="line">create trigger tri_after_insert_cmd after insert on cmd for each row</span><br><span class="line">begin</span><br><span class="line">  if NEW.success = &#x27;no&#x27; then  # 新记录都会被MySQL封装成NEW对象</span><br><span class="line">      insert into errlog(err_cmd,err_time) values(NEW.cmd,NEW.sub_time);</span><br><span class="line">  end if;</span><br><span class="line">end $$</span><br><span class="line">delimiter ;  # 结束之后记得再改回来，不然后面结束符就都是$$了</span><br></pre></td></tr></table></figure>

<p><img src="D:%5Cpycharm%5CTemporary_notes%5C%E5%9B%BE%E7%89%87%5Cimage-20240603183941620.png" alt="image-20240603183941620"></p>
<h4 id="（3）往cmd表中插入数据">（3）往cmd表中插入数据</h4>
```sql
INSERT INTO cmd (
    USER,
    priv,
    cmd,
    sub_time,
    success
)VALUES
  ('kevin','0755','ls -l /etc',NOW(),'yes'),
  ('kevin','0755','cat /etc/passwd',NOW(),'no'),
  ('kevin','0755','useradd xxx',NOW(),'no'),
  ('kevin','0755','ps aux',NOW(),'yes');
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">![image-20240603183957366](D:\pycharm\Temporary_notes\图片\image-20240603183957366.png)</span><br><span class="line"></span><br><span class="line">#### (4)查看数据</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```sql</span><br><span class="line">select * from cmd;</span><br></pre></td></tr></table></figure>

```sql
select * from errlog;
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">![image-20240603184015762](D:\pycharm\Temporary_notes\图片\image-20240603184015762.png)</span><br><span class="line"></span><br><span class="line">## 【五】自定义触发器</span><br><span class="line"></span><br><span class="line">### 【1】创建触发器</span><br><span class="line"></span><br><span class="line">- 使用数据库管理系统提供的语法，创建一个新的触发器对象。</span><br><span class="line">- 在创建触发器时，您需要指定触发器的名称、触发时机（例如在插入、更新或删除之前或之后）、触发的表以及触发时执行的逻辑。</span><br><span class="line"></span><br><span class="line">### 【2】定义触发器逻辑</span><br><span class="line"></span><br><span class="line">- 在创建触发器时，您需要定义触发器在触发时所执行的逻辑。 </span><br><span class="line">  - 这可以是任何数据库支持的操作</span><br><span class="line">- 比如插入数据、更新数据、删除数据、查询数据等。 </span><br><span class="line"></span><br><span class="line">- - 您可以使用SQL语句或调用存储过程、函数来实现触发器的逻辑。</span><br><span class="line"></span><br><span class="line">### 【3】定义触发器的条件</span><br><span class="line"></span><br><span class="line">- 指定触发条件</span><br><span class="line">  - 触发条件是一个逻辑表达式，当表中的数据满足该表达式时，触发器才会被激活执行相关的逻辑。</span><br><span class="line">  - 例如，您可以指定只有当某列的值大于特定值时才触发触发器。</span><br><span class="line"></span><br><span class="line">### 【4】绑定触发器</span><br><span class="line"></span><br><span class="line">- 将触发器绑定到相应的表上。一般情况下，触发器会与指定的表相关联，当该表发生特定的数据操作时，触发器才会被触发执行。</span><br><span class="line"></span><br><span class="line">### 【5】测试触发器</span><br><span class="line"></span><br><span class="line">- 在绑定触发器后，您可以进行一些测试操作，验证触发器的逻辑是否按照预期执行。 </span><br><span class="line"></span><br><span class="line">- - 可以插入、更新或删除数据，观察触发器是否正确地处理这些操作。</span><br><span class="line"></span><br><span class="line">## 【六】语句结束符</span><br><span class="line"></span><br><span class="line">- 在写触发器的语句时，会遇到特殊情况，需要要修改默认的语句结束符</span><br><span class="line">- 临时修改的原因是因为触发器 存储过程等技术点 代码中也需要使用分号</span><br><span class="line"></span><br><span class="line">- 如果不修改，则无法书写出完整的代码</span><br><span class="line"></span><br><span class="line">### 【1】创建触发器</span><br><span class="line"></span><br><span class="line">- 修改结束符</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```sql</span><br><span class="line">delimiter $$</span><br></pre></td></tr></table></figure>

<ul>
<li>修改结束符为了区分错误的执行语句和全局结束语句</li>
</ul>
```sql
create trigger tri_after_insert_cmd after insert on cmd 
for each row
begin
	if NEW.success = "no" then
		insert into errlog(err_cmd,err_time)
	values(NEW.cmd,NEW.sub_time);
		end if;
end $$
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">- 使用完成后记得修改回来</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```sql</span><br><span class="line">delimiter ;</span><br></pre></td></tr></table></figure>

<h3 id="【2】删除触发器">【2】删除触发器</h3>
```sql
drop tri_after_insert_cmd;
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 【七】参考模板</span><br><span class="line"></span><br><span class="line">### 【1】在表中插入新记录时，自动生成唯一标识符</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```sql</span><br><span class="line">CREATE TRIGGER generate_uuid_trigger BEFORE INSERT ON table_name</span><br><span class="line">FOR EACH ROW</span><br><span class="line">BEGIN</span><br><span class="line">    SET NEW.uuid = UUID();</span><br><span class="line">END;</span><br></pre></td></tr></table></figure>

<h3 id="【2】在表中更新记录时，更新最后修改时间">【2】在表中更新记录时，更新最后修改时间</h3>
```sql
CREATE TRIGGER generate_uuid_trigger BEFORE INSERT ON table_name
FOR EACH ROW
BEGIN
    SET NEW.uuid = UUID();
END;
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 【3】在表中删除记录时，将记录添加到历史记录表</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```sql</span><br><span class="line">CREATE TRIGGER archive_deleted_record_trigger AFTER DELETE ON table_name</span><br><span class="line">FOR EACH ROW</span><br><span class="line">BEGIN</span><br><span class="line">    INSERT INTO history_table (id, deleted_at)</span><br><span class="line">    VALUES (OLD.id, NOW());</span><br><span class="line">END;</span><br></pre></td></tr></table></figure>

<h3 id="【4】在表中插入新记录时，检查是否满足某个条件，若不满足则取消插入操作">【4】在表中插入新记录时，检查是否满足某个条件，若不满足则取消插入操作</h3>
```sql
CREATE TRIGGER check_condition_trigger BEFORE INSERT ON table_name
FOR EACH ROW
BEGIN
    IF NEW.column_name < 10 THEN
        SIGNAL SQLSTATE '45000' SET MESSAGE_TEXT = 'Value must be greater than 10';
    END IF;
END;
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">- 上述模板中的&quot;table_name&quot;和&quot;column_name&quot;应替换为您实际使用的表名和列名</span><br><span class="line"></span><br><span class="line">### 【5】日志模板</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```sql</span><br><span class="line"># 创建语句前修改默认语句结束符</span><br><span class="line">delimiter $$</span><br><span class="line"># 主要是为了区分错误执行语句和全局结束语句</span><br><span class="line">create trigger tri_after_insert_cmd after insert on cmd </span><br><span class="line">for each row</span><br><span class="line">begin</span><br><span class="line">	if NEW.success = &quot;no&quot; then</span><br><span class="line">		insert into errlog(err_cmd,err_time)</span><br><span class="line">	values(NEW.cmd,NEW.sub_time);</span><br><span class="line">		end if;</span><br><span class="line">end $$</span><br><span class="line"># 使用完以后要修改回原来的默认语句</span><br><span class="line">delimiter ;</span><br></pre></td></tr></table></figure>

<h1>MySQL进阶知识之事务</h1>
<h2 id="【一】什么是事务">【一】什么是事务</h2>
<ul>
<li>开启一个事务可以包含多条语句，这些语句要么同时成功，要么同时都不成功</li>
<li>事物的目标是确保多个操作中的每一个操作都成功执行，要么全部失败回滚</li>
</ul>
<h2 id="【二】事物的四大特性">【二】事物的四大特性</h2>
<ul>
<li>ACID</li>
</ul>
<h3 id="【1】原型性（Atomicity）">【1】原型性（Atomicity）</h3>
<ul>
<li><strong>事务被视为一个原子操作，不可再分割</strong>。</li>
<li>要么所有的操作都成功执行，要么所有的操作都会被回滚到事务开始前的状态，确保数据的一致性。</li>
</ul>
<h3 id="【2】一致性（Consistency）">【2】一致性（Consistency）</h3>
<ul>
<li><strong>事务执行前后，数据库应保持一致的状态</strong></li>
<li>在事物开始之前和结束之后，数据库必须满足所有的完整性约束，如数据类型、关系等</li>
</ul>
<h3 id="【3】隔离性（Isolation）">【3】隔离性（Isolation）</h3>
<ul>
<li><strong>事务的执行结果对其他并发执行的事务是隔离的。</strong></li>
<li>即一个事务的执行不应受到其他事务的干扰，各个事务之间应该相互独立工作，从而避免数据的不一致性。</li>
</ul>
<h3 id="【4】持久性-Durability">【4】持久性(Durability)</h3>
<ul>
<li><strong>也叫永久性</strong></li>
<li><strong>一旦事务被提交，其结果应该永久保存在数据库中，并且可以被系统故障恢复。</strong></li>
<li>即使系统发生宕机或崩溃，事务提交后的更改也应该是永久性的。</li>
</ul>
<h2 id="【三】事物的作用">【三】事物的作用</h2>
<ul>
<li>在操作多条数据的时候，可能会出现某几条操作不成功的情况</li>
</ul>
<h3 id="【1】数据库的一致性">【1】数据库的一致性</h3>
<ul>
<li>事务可以保证数据库的一致性</li>
<li>在一个事务中，要么所有操作都成功，要么全部回滚，保证了数据的完整性和一致性</li>
</ul>
<p>案例</p>
<ul>
<li><strong>在一个转账操作中，如果转出账户扣款成功而转入账户未能成功接收资金，事务可以将操作全部回滚，以确保资金的一致性。</strong></li>
</ul>
<h3 id="【2】并发控制">【2】并发控制</h3>
<ul>
<li>事务提供了并发控制机制，确保多个并发的事务不会互相干扰，并避免了数据的混乱和冲突</li>
<li>通过隔离级别的设置，事务可以控制不同事务之间的可见性和影响范围，保证并发执行时的数据一致性和隔离性</li>
</ul>
<h3 id="【3】故障恢复">【3】故障恢复</h3>
<ul>
<li>事务的持久特性确保了在事务提交后，即使系统发生了故障或崩溃，提交的结果仍然可以被恢复</li>
<li>数据库管理系统通过使用日志文件等机制，将事务的操作记录下来，以便在需要时进行恢复和重放</li>
</ul>
<h3 id="【4】高效运行">【4】高效运行</h3>
<ul>
<li>通过组织多个操作为一个事务，可以减少与数据库交互的次数，从而提高数据库的操作效率和性能</li>
<li>事务可以减少磁盘I/O、锁的竞争等操作开销，提高数据库的并发处理能力</li>
</ul>
<h3 id="【5】数据完整性和安全性">【5】数据完整性和安全性</h3>
<ul>
<li>事务可以保证数据的完整性和安全性</li>
<li>通过在事务中定义一些条件和约束，可以确保数据的有效性和准确性</li>
<li><strong>例如，在一个银行系统中，事务可以检查账户余额是否足够以及转账金额是否合法，从而保证数据的安全性和正确性</strong></li>
</ul>
<h3 id="【6】用户提交订单操作案例">【6】用户提交订单操作案例</h3>
<ul>
<li>
<p>检查库存：</p>
</li>
<li>
<ul>
<li>系统需要检查所需商品的库存是否足够。</li>
<li>如果库存不足，系统会提示用户库存不足，无法完成订单。</li>
</ul>
</li>
<li>
<p>扣减库存：</p>
</li>
<li>
<ul>
<li>如果库存充足，系统会将所购商品对应的库存数量减少。</li>
</ul>
</li>
<li>
<p>生成订单：</p>
</li>
<li>
<ul>
<li>系统会生成一个新的订单，包括订单号、商品信息、购买数量、价格等相关信息。</li>
</ul>
</li>
<li>
<p>计算总价：</p>
</li>
<li>
<ul>
<li>根据订单中的商品信息和购买数量，系统会计算出订单的总价格。</li>
</ul>
</li>
<li>
<p>更新用户账户：</p>
</li>
<li>
<ul>
<li>根据用户选择的支付方式，在扣除相应金额后，系统会更新用户账户余额或积分。</li>
</ul>
</li>
<li>
<p>生成支付信息：</p>
</li>
<li>
<ul>
<li>系统会生成相应的支付信息，以便用户完成支付。</li>
</ul>
</li>
<li>
<p>通知物流部门：</p>
</li>
<li>
<ul>
<li>系统会通知物流部门准备配送相关商品。</li>
</ul>
</li>
<li>
<p>发送订单确认邮件/短信：</p>
</li>
<li>
<ul>
<li>系统会向用户发送订单确认的邮件或短信，包括订单详细信息、配送信息等。</li>
</ul>
</li>
<li>
<p>监控商品配送：</p>
</li>
<li>
<ul>
<li>系统会跟踪订单的配送情况，并向用户提供订单状态更新。</li>
</ul>
</li>
<li>
<p>完成订单：</p>
</li>
<li>
<ul>
<li>当用户收到商品并确认满意后，订单状态会被更新为“已完成”。</li>
</ul>
</li>
</ul>
<h2 id="【四】如何使用事务">【四】如何使用事务</h2>
<h3 id="【1】事务的关键字">【1】事务的关键字</h3>
<ul>
<li>开启事务
<ul>
<li><code>start transaction;</code></li>
</ul>
</li>
<li>回滚（回到事务之前的操作）
<ul>
<li><code>rollback;</code></li>
</ul>
</li>
<li>二次确认(确认之后无法回滚)
<ul>
<li><code>commit;</code></li>
</ul>
</li>
<li>当多个数据库操作需要作为一个整体进行提交或回滚时，可以使用事务来实现</li>
</ul>
<h3 id="【2】使用事务的基本步骤">【2】使用事务的基本步骤</h3>
<h4 id="（1）开启">（1）开启</h4>
<h1>MySQL进阶知识之存储过程</h1>
<h1>MySQL进阶知识之函数</h1>
<h1>MySQL进阶知识之流程控制</h1>
<h1>MySQL进阶知识之索引</h1>
<h1>MySQL进阶知识之事务隔离机制</h1>
<h2 id="【一】数据库读现象的本质">【一】数据库读现象的本质</h2>
<ul>
<li>是数据库在高并发场景下</li>
<li>多个同时执行的事务带来的影响。</li>
</ul>
<h2 id="【二】数据库三大读现象">【二】数据库三大读现象</h2>
<ul>
<li>在数据库中，不同的事务隔离级别可能会导致脏读（Dirty Read）、不可重复读（Non-repeatable Read）和幻读（Phantom Read）等问题的出现。</li>
</ul>
<h3 id="【1】脏读">【1】脏读</h3>
<h4 id="（1）概述">（1）概述</h4>
<ul>
<li>事务1和事务2并发执行</li>
<li>事务1改了数据</li>
<li>事务2读取了以后</li>
<li>但事务1进行了回滚</li>
<li>导致事务2读取的数据有误。</li>
</ul>
<h4 id="（2）解释">（2）解释</h4>
<ul>
<li>脏读是指当一个事务读取了其他事务尚未提交的数据时发生的现象。</li>
<li>换句话说，脏读表示读取到的数据并不一定会最终存入数据库中，因此这些数据实际上是不存在的。</li>
<li>脏读现象发生在读取到了不一定存在的数据的情况下。</li>
</ul>
<h4 id="（3）总结">（3）总结</h4>
<ul>
<li>脏读指的是读当前事务到了其他事务未提交的数据，未提交意味着这些数据可能会回滚，</li>
<li>也就是可能最终不会存到数据库中，也就是不存在的数据。读到了并一定最终存在的数据，这就是脏读</li>
</ul>
<h3 id="【2】不可重复读">【2】不可重复读</h3>
<h4 id="（1）概述-2">（1）概述</h4>
<ul>
<li>事务1读取了数据</li>
<li>事务2修改了数据并且提交了</li>
<li>接着事务1再次读取</li>
<li>发现两次的数据不相同</li>
</ul>
<h4 id="（2）解释-2">（2）解释</h4>
<ul>
<li>不可重复读是指在一个事务内多次读取同一批数据，但在事务结束之前，这批数据可能发生了变化，导致读取结果不一致的情况。</li>
<li>不可重复读的产生通常是由于在事务A多次读取同一数据的过程中，事务B对数据进行了更新并提交。</li>
</ul>
<h4 id="（3）总结-2">（3）总结</h4>
<ul>
<li>解释：不可重复读指的是在一个事务内，最开始读到的数据和事务结束前的任意时刻读到的同一批数据出现不一致的情况</li>
<li>导致的原因：事务 A 多次读取同一数据，但事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果 不一致</li>
</ul>
<h3 id="【3】幻读">【3】幻读</h3>
<h4 id="（1）概述-3">（1）概述</h4>
<ul>
<li>本质上说是不可重复读的一种现象</li>
<li>事务1更改或查询了数据</li>
<li>在极短时间内,事务2又插入了一条新的数据</li>
<li>导致事务1在接下来的查询中</li>
<li>就会发现有⼏列数据是它先前所没有的。</li>
</ul>
<h4 id="（2）错误的理解">（2）错误的理解</h4>
<h5 id="1-解释">[1]解释</h5>
<ul>
<li>
<p>有时候，人们错误地将幻读理解为在两次select操作中获得了不同的数据集</p>
</li>
<li>
<ul>
<li>例如第一次select得到10条记录</li>
<li>第二次select得到15条记录。</li>
</ul>
</li>
<li>
<p>实际上，这种情况仍然属于不可重复读而非幻读。</p>
</li>
</ul>
<h5 id="2-总结">[2]总结</h5>
<ul>
<li>幻读是 事务A 执行两次 select 操作得到不同的数据集，即 select 1 得到 10 条记录，select 2 得到 15 条记录。</li>
<li>这其实并不是幻读，既然第一次和第二次读取的不一致，那不还是不可重复读吗，所以这是不可重复读的一种。</li>
</ul>
<h4 id="（3）正确的理解">（3）正确的理解</h4>
<h5 id="1-解释-2">[1]解释</h5>
<ul>
<li>幻读的本质在于某一次select操作得到的结果无法支撑后续的业务操作。</li>
<li>具体来说，例如在执行select判断某条记录是否存在时，假设该记录不存在，准备插入该记录，但在执行insert时却发现该记录已经存在，导致无法插入，这即是幻读的发生。</li>
</ul>
<h5 id="2-总结-2">[2]总结</h5>
<ul>
<li>幻读，并不是说两次读取获取的结果集不同，幻读侧重的方面是某一次的 select 操作得到的结果所表征的数据状态无法支撑后续的业务操作。</li>
<li>更为具体一些：select 某记录是否存在，不存在，准备插入此记录，但执行 insert 时发现此记录已存在，无法插入，此时就发生了幻读</li>
</ul>
<h3 id="【4】解决办法">【4】解决办法</h3>
<ul>
<li>要解决脏读，不可重复读和幻读的问题</li>
<li>我们就要引入几个概念：MVCC机制，事务隔离机制和数据库锁机制。</li>
</ul>
<h2 id="【三】数据库事务隔离机制">【三】数据库事务隔离机制</h2>
<ul>
<li>事务具有原子性、一致性、隔离性、持久性四大特性</li>
</ul>
<h3 id="【1】事务的四大特性-ACID">【1】事务的四大特性(ACID)</h3>
<h4 id="（1）原子性（Atomicity）">（1）原子性（Atomicity）</h4>
<ul>
<li>事务是一个不可再分割的单位，要么全部执行成功，要么全部回滚到初始状态，没有中间状态。</li>
<li>这意味着如果事务中的任何一步操作失败，整个事务都会被回滚，以确保数据的一致性。</li>
</ul>
<h4 id="（2）一致性（Consistency）">（2）一致性（Consistency）</h4>
<ul>
<li>事务执行前后，数据库的状态必须保持一致。</li>
<li>这意味着事务在执行期间对数据的操作必须满足预定义的规则和完整性约束，以确保数据的有效性和正确性。</li>
</ul>
<h4 id="（3）隔离性（Isolation）">（3）隔离性（Isolation）</h4>
<ul>
<li>多个事务可能同时执行，事务之间应该相互隔离，互不影响。</li>
<li>隔离性确保每个事务的操作在逻辑上独立于其他并发事务的操作，从而避免了数据不一致的问题。</li>
</ul>
<h4 id="（4）持久性（Durability）">（4）持久性（Durability）</h4>
<ul>
<li>一旦事务提交，对数据库的更改应该是永久性的，即使在系统故障的情况下也不应该丢失。</li>
<li>持久性通过将事务记录在持久存储介质（如磁盘）上来实现。</li>
</ul>
<h3 id="【2】隔离性的四种级别">【2】隔离性的四种级别</h3>
<h4 id="（1）引入">（1）引入</h4>
<ul>
<li>
<p>而隔离性顾名思义指的就是事务彼此之间隔离开</p>
</li>
<li>
<ul>
<li>多个事务在同时处理一个数据时彼此之间互相不影响</li>
<li>如如果隔离的不够好就有可能会产生脏读、不可重复度、幻读等读现象</li>
</ul>
</li>
<li>
<p>为此，隔离性总共分为四种级别</p>
</li>
<li>
<p>由低到高依次为</p>
</li>
<li>
<ul>
<li>Read uncommitted（未提交读）</li>
<li>Read committed （提交读）</li>
<li>Repeatable read（可重复读）</li>
<li>Serializable（串行化）</li>
</ul>
</li>
</ul>
<h4 id="（2）四种级别">（2）四种级别</h4>
<h5 id="1-Read-uncommitted（读未提交）">[1]Read uncommitted（读未提交）</h5>
<ul>
<li>最低的隔离级别，在这个级别下，一个事务可以读取到另一个事务尚未提交的数据，可能导致脏读（Dirty Read）问题，即读取到未经验证的数据。</li>
</ul>
<h5 id="2-Read-committed（读已提交）">[2]Read committed（读已提交）</h5>
<ul>
<li>在这个级别下，一个事务只能读取到已经提交的数据，避免了脏读问题。</li>
<li>但是可能会出现不可重复读（Non-repeatable Read）问题，即同一事务中，两次读取相同的记录可能得到不同的结果，因为其他事务修改了这些记录。</li>
</ul>
<h5 id="3-Repeatable-read（可重复读取）">[3]Repeatable read（可重复读取）</h5>
<ul>
<li>在这个级别下，事务开始读取数据后，其他事务无法修改这些数据，保证了同一个事务内两次读取相同记录的一致性。</li>
<li>但是可能会出现幻读（Phantom Read）问题，即同一查询在同一事务中两次执行可能返回不同的结果，因为其他事务插入或删除了符合查询条件的记录。</li>
</ul>
<h5 id="4-Serializable（串行化）">[4]Serializable（串行化）</h5>
<ul>
<li>最高级别的隔离级别，要求事务串行执行，事务之间完全隔离，避免了脏读、不可重复读和幻读问题。</li>
<li>但是这会牺牲并发性能，因为并发事务被限制为顺序执行。</li>
</ul>
<h3 id="【3】四大隔离级别解决了什么问题">【3】四大隔离级别解决了什么问题</h3>
<ul>
<li>
<p>Read uncommitted（读未提交）</p>
</li>
<li>
<ul>
<li><strong>存在脏读、不可重复读和幻读问题</strong>。</li>
</ul>
</li>
<li>
<p>Read committed（读已提交）</p>
</li>
<li>
<ul>
<li><strong>解决了脏读问题</strong>，但<strong>仍可能出现不可重复读和幻读</strong>。</li>
</ul>
</li>
<li>
<p>Repeatable read（可重复读取）</p>
</li>
<li>
<ul>
<li><strong>解决了脏读和不可重复读问题</strong>，但<strong>仍可能出现幻读</strong>。</li>
</ul>
</li>
<li>
<p>Serializable（串行化）</p>
</li>
<li>
<ul>
<li><strong>解决了脏读、不可重复读和幻读问题</strong>，但在<strong>效率方面有所牺牲</strong>。</li>
</ul>
</li>
</ul>
<h3 id="【4】MySQL的存储引擎默认的隔离级别">【4】MySQL的存储引擎默认的隔离级别</h3>
<ul>
<li>Repratable read (可重复读)</li>
</ul>
<h3 id="【5】幻读的解决办法">【5】幻读的解决办法</h3>
<ul>
<li>MySQL引入了Next-key lock的行级锁来解决，我们将会在下一节里详细叙述</li>
</ul>
<h2 id="【四】MVCC机制">【四】MVCC机制</h2>
<h3 id="【1】什么是MVCC机制">【1】什么是MVCC机制</h3>
<ul>
<li>MVCC是MySQL InnoDB存储引擎实现的一种基于多版本的并发控制协议。</li>
<li>基于多版本的并发控制协议——MVCC (Multi-Version Concurrency Control) 。</li>
</ul>
<h3 id="【2】MVCC的优势">【2】MVCC的优势</h3>
<ul>
<li>MVCC实现了读不加锁，避免了读写冲突，提高了系统的并发性能。</li>
<li>MVCC解决了数据的脏读问题，保证了数据的一致性。</li>
</ul>
<h3 id="【3】MVCC的读操作">【3】MVCC的读操作</h3>
<ul>
<li>MVCC的并发控制的系统中，读操作可分为两类：当前读和快照读。</li>
</ul>
<h4 id="（1）快照读">（1）快照读</h4>
<ul>
<li>快照读是指对数据库进行简单的select操作时，不会加锁，而是通过查询当前事务开始时的系统时间点，获取该时间点之前的数据副本。</li>
<li>由于每个事务都有自己的时间点，所以每个事务看到的都是自己创建时的状态，从而避免了脏读的发生。</li>
</ul>
<h4 id="（2）当前读">（2）当前读</h4>
<ul>
<li>特殊的读操作，插入/更新/删除操作，属于当前读，需要加锁。</li>
<li>当前读是指对数据库进行插入、更新或删除操作时，需要加锁，以防止其他事务修改已经锁定的数据。只有当事务完成所有更新后，才会将其提交到数据库，并释放所有的锁。</li>
<li>这种机制可以确保数据的一致性和完整性，但会降低系统的并发性能。</li>
</ul>
<h1>MySQL进阶知识之锁机制</h1>
<h2 id="【一】什么是锁机制">【一】什么是锁机制</h2>
<ul>
<li>
<p>我们可以通过一个很简单的比喻来理解事务的锁机制。</p>
</li>
<li>
<p>比如同一个办公室的同事们</p>
</li>
<li>
<ul>
<li>都想使用打印机打印文件</li>
</ul>
</li>
<li>
<ul>
<li>
<ul>
<li>如果不加以控制</li>
<li>可能出现两个人同时打印不同的内容在一个文件里</li>
<li>就会引起内容混乱。</li>
</ul>
</li>
</ul>
</li>
<li>
<ul>
<li>于是，我们就引入了锁的概念</li>
</ul>
</li>
<li>
<ul>
<li>
<ul>
<li>当有并发的多个事务同时操作同一份数据时</li>
<li>只有“抢到”了锁的事务</li>
<li>才能真正去操作数据</li>
<li>使得数据的安全性得到保证。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="【二】为什么要用锁机制">【二】为什么要用锁机制</h2>
<ul>
<li>
<p>锁保证并发的多个事务同一时间只有一个能运行</p>
</li>
<li>
<ul>
<li>会一定程度上降低程序的运行效率</li>
<li>但是能大大提升数据的安全性。</li>
</ul>
</li>
</ul>
<h2 id="【三】数据库锁的分类">【三】数据库锁的分类</h2>
<h3 id="【1】按粒度分">【1】按粒度分</h3>
<ul>
<li>
<p>数据库的锁按粒度分为</p>
</li>
<li>
<ul>
<li>行级锁</li>
<li>表级锁</li>
<li>页级锁</li>
</ul>
</li>
</ul>
<h4 id="（1）什么是⾏级锁">（1）什么是⾏级锁</h4>
<ul>
<li>
<p>⾏级锁是Mysql中锁定粒度最细的⼀种锁</p>
</li>
<li>
<ul>
<li>表示只针对当前操作的⾏进⾏加锁。</li>
</ul>
</li>
<li>
<p>⾏级锁能⼤⼤减少数据库操作的冲突。</p>
</li>
<li>
<ul>
<li>其加锁粒度最⼩，但加锁的开销也最⼤。</li>
</ul>
</li>
<li>
<p>⾏级锁分为共享锁和排他锁。</p>
</li>
</ul>
<h4 id="（2）⾏级锁的特点">（2）⾏级锁的特点</h4>
<ul>
<li>开销⼤，加锁慢；</li>
<li>会出现死锁；</li>
<li>锁定粒度最⼩，发⽣锁冲突的概率最低，并发度也最⾼</li>
</ul>
<h4 id="（3）⾏级锁解释">（3）⾏级锁解释</h4>
<ul>
<li>
<p>由于数据库的库和表都是事先建好的</p>
</li>
<li>
<ul>
<li>所以我们针对数据库的操作一般都是针对记录。</li>
<li>而对记录进行的四种操作（增删改查）</li>
<li>我们可以分为两类</li>
</ul>
</li>
<li>
<ul>
<li>
<ul>
<li>增删改属于读操作</li>
<li>而查询属于写操作。</li>
</ul>
</li>
</ul>
</li>
<li>
<p>写操作默认就会加锁，且加的是互斥锁</p>
</li>
<li>
<ul>
<li>很容易理解，在进行写行为的时候一定是必须“排他”的。</li>
<li>读操作默认不受任何锁影响</li>
<li>但是互斥锁和共享锁都可以加。</li>
</ul>
</li>
<li>
<p>读操作加互斥锁 for update;</p>
</li>
<li>
<p>读操作加共享锁 lock in share mode;</p>
</li>
</ul>
<p>提示：关于共享锁和互斥锁，我们将在下一小节更详细地讲述</p>
<h4 id="（4）行级锁锁的是索引">（4）行级锁锁的是索引</h4>
<ul>
<li>
<p>行级锁锁的是索引</p>
</li>
<li>
<ul>
<li>命中索引以后才会锁行</li>
<li>如果没有命中索引</li>
<li>会把整张表都锁起来。</li>
</ul>
</li>
<li>
<p>命中主键索引就锁定这条语句命中的主键索引</p>
</li>
<li>
<ul>
<li>命中辅助索引就会先锁定这条辅助索引</li>
<li>再锁定相关的主键索引</li>
<li>考虑到性能，innodb默认支持行级锁</li>
<li>但是只有在命中索引的情况下才锁行，</li>
</ul>
</li>
<li>
<p>否则锁住所有行</p>
</li>
<li>
<ul>
<li>本质还是行锁</li>
<li>但是此刻相当于锁表了</li>
</ul>
</li>
</ul>
<h4 id="（5）行级锁的三种算法">（5）行级锁的三种算法</h4>
<ul>
<li>
<p>1、Record lock</p>
</li>
<li>
<p>2、Gap lock</p>
</li>
<li>
<p>3、Next-key lock</p>
</li>
<li>
<p>其中 Next-key lock 为MySQL默认的锁机制</p>
</li>
<li>
<ul>
<li>相当于另外两种锁的功能的整合</li>
<li>并能够解决幻读问题。</li>
</ul>
</li>
<li>
<p>提示：</p>
</li>
<li>
<ul>
<li>在RR事务隔离机制下，才会锁间隙</li>
<li>而RR机制是mysql的默认事务隔离机制。</li>
<li>所以，在默认情况下，其实innodb存储引擎锁的是行以及间隙.</li>
</ul>
</li>
<li>
<p>我们可以用一个实验来验证上述关于行锁的结论</p>
</li>
</ul>
<h4 id="（6）实验">（6）<strong>实验</strong></h4>
<table>
<thead>
<tr>
<th>事务一</th>
<th>事务二</th>
</tr>
</thead>
<tbody>
<tr>
<td>start transaction;</td>
<td>开启事务start transaction;</td>
</tr>
<tr>
<td></td>
<td>– 加排他锁select from t1 where id=7 for update; – 须知-- 1、上述语句命中了索引，所以加的是行锁-- 2、InnoDB对于行的查询都是采用了Next-Key Lock的算法，锁定的不是单个值，而是一个范围（GAP）表记录的索引值为1，5，7，11，其记录的GAP区间如下：（-∞,1]，(1,5]，(5,7]，(7,11]，(11,+∞）因为记录行默认就是按照主键自增的，所以是一个左开右闭的区间其中上述查询条件id=7处于区间(5,7]中，所以Next-Key lock会锁定该区间的记录，但是还没完-- 3、<em>InnoDB存储引擎还会对辅助索引下一个键值加上gap lock</em>*。区间(5,7]的下一个Gap是(7,11],所以(7,11]也会被锁定综上所述，最终确定5-11之间的值都会被锁定</td>
</tr>
<tr>
<td>– 下述sql全都会阻塞在原地insert t1 values(5);insert t1 values(6);insert t1 values(7);insert t1 values(8);insert t1 values(9);insert t1 values(10); – 下述等sql均不会阻塞insert t1 values(11); insert t1 values(1); insert t1 values(2);insert t1 values(3);insert t1 values(4);</td>
<td></td>
</tr>
<tr>
<td>– 提交一下事务，不要影响下一次实验commit;</td>
<td>– 提交一下事务，不要影响下一次实验commit;</td>
</tr>
</tbody>
</table>
<h3 id="【2】按级别分">【2】按级别分</h3>
<ul>
<li>
<p>数据库的锁按级别分为</p>
</li>
<li>
<ul>
<li>共享锁，排他锁，共享锁</li>
<li>又被称作读锁，s锁</li>
</ul>
</li>
<li>
<ul>
<li>
<ul>
<li>含义是多个事务共享同一把锁</li>
<li>其中每个事务都能访问到数据</li>
<li>但是没有办法进行修改。</li>
</ul>
</li>
</ul>
</li>
<li>
<p>注意：</p>
</li>
<li>
<ul>
<li>如果事务T对数据A加上共享锁后</li>
<li>则其他事务只能对A再加共享锁或不加锁（在其他事务里一定不能再加排他锁</li>
<li>但是在事务T自己里面是可以加的）</li>
</ul>
</li>
<li>
<p>排他锁又被称作互斥锁，写锁，x锁</p>
</li>
<li>
<ul>
<li>含义是如果有一个事务获取了一个数据的排他锁</li>
<li>那么其它的事务都无法再次获得该数据的任何锁了</li>
<li>但是排他锁支持文件读取，修改和写入。</li>
</ul>
</li>
</ul>
<h3 id="【3】按使用方式分">【3】按使用方式分</h3>
<ul>
<li>
<p>数据库的锁按使用方式分为</p>
</li>
<li>
<ul>
<li>悲观锁、乐观锁</li>
</ul>
</li>
</ul>
<h4 id="（1）悲观锁（Pessimistic-Locking）">（1）悲观锁（Pessimistic Locking）</h4>
<ul>
<li>顾名思义指的是对外界将要进行的数据修改操作持悲观态度</li>
<li>因此，在整个数据处理过程中，将数据处于锁定状态。</li>
<li>现在由于互联网的高并发架构，即使加上悲观锁也无法保证数据不被外界修改，因此不推荐使用。</li>
</ul>
<h4 id="（2）乐观锁（Optimistic-Locking）">（2）乐观锁（Optimistic Locking）</h4>
<ul>
<li>
<p>相对悲观锁而言，乐观锁假设认为数据一般情况下不会造成冲突</p>
</li>
<li>
<p>所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测</p>
</li>
<li>
<p>如果发现冲突了，则让返回用户错误的信息，让用户决定如何去做。</p>
</li>
<li>
<p>通常乐观锁的实现是在表中加一个字段（可能是时间戳或版本号）</p>
</li>
<li>
<p>在写入的时候会查询一下版本号</p>
</li>
<li>
<ul>
<li>如果版本号没有改变，就写入数据库并同时改变版本号。</li>
</ul>
</li>
<li>
<p>从本质上来说，乐观锁并没有加锁</p>
</li>
<li>
<ul>
<li>所以效率会大大提升</li>
<li>但也有一定的缺陷，就是可能导致一部分任务的写入失败。</li>
</ul>
</li>
</ul>
<h2 id="【四】死锁问题">【四】死锁问题</h2>
<ul>
<li>
<p>我们举一个例子来形象的说明死锁这个概念。</p>
</li>
<li>
<p>比如你和你的邻居同时被锁在了屋子里</p>
</li>
<li>
<ul>
<li>然而你有你邻居的钥匙</li>
<li>你的邻居也有你的钥匙</li>
<li>你们互相可以打开对方的房门</li>
<li>但是却都被锁在了各自的屋子里</li>
<li>这就是一个简单的死锁现象</li>
</ul>
</li>
</ul>
<h3 id="【1】第一种情况的死锁">【1】第一种情况的死锁</h3>
<table>
<thead>
<tr>
<th>事务1</th>
<th>事务2</th>
</tr>
</thead>
<tbody>
<tr>
<td>begin</td>
<td>begin</td>
</tr>
<tr>
<td>select * from t1 where id=6 for update;</td>
<td>delete from t1 where id=3;</td>
</tr>
<tr>
<td>update t1 set age=18 where id=3;</td>
<td>delete from t1 where id=6; – 阻塞</td>
</tr>
</tbody>
</table>
<ul>
<li>
<p>第一种死锁情况非常好理解，也是最常见的死锁</p>
</li>
<li>
<ul>
<li>每个事务执行两条SQL，分别持有了一把锁</li>
<li>然后加另一把锁，产生死锁。</li>
</ul>
</li>
<li>
<p>大多数死锁问题</p>
</li>
<li>
<ul>
<li>innodb存储引擎都会发现并抛出异常</li>
<li>但是有一种死锁问题极其隐蔽。</li>
</ul>
</li>
</ul>
<h3 id="【2】第二种情况的死锁">【2】第二种情况的死锁</h3>
<ul>
<li>
<p>与上一种死锁情况不同的是</p>
</li>
<li>
<ul>
<li>这种死锁现象必须是两个事务同时运行的情况下才可能发生。</li>
</ul>
</li>
<li>
<p>前面我们提到过，聚集索引对应的是一整行数据记录。</p>
</li>
<li>
<ul>
<li>当事务1根据一定的过滤条件</li>
<li>筛选出两条辅助索引时</li>
<li>根据索引的有序性</li>
<li>在锁完辅助索引后锁主键索引时</li>
<li>先锁主键1对应的记录再锁主键2。</li>
<li>如果在此同时</li>
</ul>
</li>
<li>
<ul>
<li>
<ul>
<li>事务2通过别的辅助索引同样访问到了这两条数据</li>
<li>但顺序却是先锁主键2再锁主键1</li>
<li>就会互相锁住</li>
<li>产生死锁现象</li>
<li>而且这种情况非常隐蔽，较难排查。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1>数据库的三大范式</h1>
<h2 id="【一】什么是范式">【一】什么是范式</h2>
<ul>
<li>范式就是我们设计数据库的表时，一些共同遵循的规范</li>
<li>掌握这些设计时的范式，可以让我们的项目之初，设计库的表结构更加合理和优雅</li>
</ul>
<h2 id="【二】三大范式之间的关系">【二】三大范式之间的关系</h2>
<ul>
<li>三大范式之间是递增的关系，一个范式是在前一个范式的基础上推行</li>
<li>三大范式之间不可颠倒，后者都是建立在前者之上</li>
</ul>
<h2 id="【三】第一范式（1NF）">【三】第一范式（1NF）</h2>
<h3 id="【1】什么是第一范式">【1】什么是第一范式</h3>
<ul>
<li>表库设计时，主要是确保原子性，也就是确保数据具有不可再分性</li>
<li>这里的原子性和MySQL特点中的原子性不同</li>
</ul>
<h3 id="【2】第一范式的原子性">【2】第一范式的原子性</h3>
<ul>
<li>指一个字段不可再分割，其中不可包含其它更小的数据单元</li>
<li>就是说一个字段的数据不能再被进一步分解为更小的数据单元</li>
</ul>
<h4 id="（1）例子说明">（1）例子说明</h4>
```sql
-- 比如我们有一张表
-- 表的结构如下

+----------------------+--------+-------+
| student              | course | score |
+----------------------+--------+-------+
| 蚩梦，男，185cm      | 语文   |    95 |
| 蚩梦，男，185cm      | 数学   |   100 |
| 蚩梦，男，185cm      | 英语   |    88 |
| 萌萌，女，170cm      | 语文   |    99 |
| 萌萌，女，170cm      | 数学   |    90 |
| 萌萌，女，170cm      | 英语   |    95 |
+----------------------+--------+-------+
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">- student明显不符合我们第一范式的要求</span><br><span class="line">  - 第一规范的要求---》**一个字段不可再分割，其中不可包含其它更小的数据单元**</span><br><span class="line">- student字段还是可以在继续拆分</span><br><span class="line"></span><br><span class="line">#### （2）基于第一范式优化</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```sql</span><br><span class="line">+--------------+-------------+----------------+--------+-------+</span><br><span class="line">| student_name | student_sex | student_height | course | score |</span><br><span class="line">+--------------+-------------+----------------+--------+-------+</span><br><span class="line">| 蚩梦         | 男          | 185cm          | 语文   |    95 |</span><br><span class="line">| 蚩梦         | 男          | 185cm          | 数学   |   100 |</span><br><span class="line">| 蚩梦         | 男          | 185cm          | 英语   |    88 |</span><br><span class="line">| 萌萌         | 女          | 170cm          | 语文   |    99 |</span><br><span class="line">| 萌萌         | 女          | 170cm          | 数学   |    90 |</span><br><span class="line">| 萌萌         | 女          | 170cm          | 英语   |    95 |</span><br><span class="line">+--------------+-------------+----------------+--------+-------+</span><br></pre></td></tr></table></figure>

<ul>
<li>将student字段拆分成三个字段后，这张表符合了第一范式的规范</li>
</ul>
<h4 id="（3）如果不去拆分列满足第一范式，会造成什么影响呢？">（3）如果不去拆分列满足第一范式，会造成什么影响呢？</h4>
<ul>
<li>我们使用不符合第一范式的表结构去做业务开发时，操作会比较麻烦一些，当我们进行符合第一范式的二次设计后，虽然表的字段变多了，但是数据结构变得清晰了很多</li>
</ul>
<h4 id="（4）第一范式（1NF）">（4）第一范式（1NF）</h4>
<ul>
<li>第一范式我们通常叫 1NF</li>
<li>第一范式要求我们必须遵守原子性
<ul>
<li>及数据库的每一列都是不可分割
<ul>
<li>每列的值具有原子性，不可再分割</li>
<li>每个字段的值都只能是单一值</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="【四】第二范式（2NF）">【四】第二范式（2NF）</h2>
<h3 id="【1】什么是第二范式">【1】什么是第二范式</h3>
<ul>
<li>第二范式是满足第一范式的基础上</li>
<li>第二范式要求表中的所有列，其数据依赖于主键
<ul>
<li>既一张表只存储同一类型的数据，不能有任何一列数据的主键没有关系</li>
</ul>
</li>
</ul>
<h3 id="【2】案例（第二范式）">【2】案例（第二范式）</h3>
<h4 id="（1）基于第一范式的表">（1）基于第一范式的表</h4>
```sql
+--------------+-------------+----------------+--------+-------+
| student_name | student_sex | student_height | course | score |
+--------------+-------------+----------------+--------+-------+
| 蚩梦         | 男          | 185cm          | 语文   |    95 |
| 蚩梦         | 男          | 185cm          | 数学   |   100 |
| 蚩梦         | 男          | 185cm          | 英语   |    88 |
| 萌萌         | 女          | 170cm          | 语文   |    99 |
| 萌萌         | 女          | 170cm          | 数学   |    90 |
| 萌萌         | 女          | 170cm          | 英语   |    95 |
+--------------+-------------+----------------+--------+-------+
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#### (2)基于第二范式进行优化</span><br><span class="line"></span><br><span class="line">- 表一</span><br><span class="line">  - student：学生</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```sql</span><br><span class="line">+------------+--------+------+--------+--------------+--------------+</span><br><span class="line">| student_id | name   | sex  | height | department   | dean         |</span><br><span class="line">+------------+--------+------+--------+--------------+--------------+</span><br><span class="line">|          1 | 蚩梦   | 男   | 185cm  | 计算机系     | 竹子老大     |</span><br><span class="line">|          2 | 萌萌   | 女   | 170cm  | 金融系       | 熊猫老大     |</span><br><span class="line">+------------+--------+------+--------+--------------+--------------+</span><br></pre></td></tr></table></figure>

<ul>
<li>表二
<ul>
<li>course：学科</li>
</ul>
</li>
</ul>
```sql
+-----------+-------------+
| course_id | course_name |
+-----------+-------------+
|         1 | 语文        |
|         2 | 数学        |
|         3 | 英语        |
+-----------+-------------+
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">- 表三</span><br><span class="line">  - score :成绩</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```sql</span><br><span class="line">+----------+------------+-----------+-------+</span><br><span class="line">| score_id | student_id | course_id | score |</span><br><span class="line">+----------+------------+-----------+-------+</span><br><span class="line">|        1 |          1 |         1 |    95 |</span><br><span class="line">|        2 |          1 |         2 |   100 |</span><br><span class="line">|        3 |          1 |         3 |    88 |</span><br><span class="line">|        4 |          2 |         1 |    99 |</span><br><span class="line">|        5 |          2 |         2 |    90 |</span><br><span class="line">|        6 |          2 |         3 |    95 |</span><br><span class="line">+----------+------------+-----------+-------+</span><br></pre></td></tr></table></figure>

<ul>
<li>
<p>小结：</p>
<ul>
<li>
<p>我们将原来的第一范式优化的表拆成了三份</p>
</li>
<li>
<p>每张表的id作为自己本表的主键，其他字段都依赖于自己的主键</p>
</li>
<li>
<p>无论那张表都可以根据主键id获得其它字段的值</p>
</li>
<li>
<p>我们可以看出经过第二范式优化后，每张表都有各自的业务属性，都具有唯一性</p>
<ul>
<li>每张表只描述一件事</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="【3】小结">【3】小结</h3>
<ul>
<li>
<p>第二范式也叫做2NF</p>
<ul>
<li>第二范式是基于第一范式的基础上建立起来的</li>
<li>满足第二范式必须先满足第一范式</li>
</ul>
</li>
<li>
<p>第一范式要求我们必须遵守原子性</p>
</li>
<li>
<p>第二范式要求表中的所有列，其数据依赖于主键</p>
</li>
<li>
<ul>
<li>即一张表只存储同一类型的数据，不能有任何一列数据与主键没有关系</li>
</ul>
</li>
<li>
<ul>
<li>
<ul>
<li>如果表是单主键，那么主键以外的列必须完全依赖于主键，其它列需要跟主键有关系</li>
<li>如果表是复合主键，那么主键以外的列必须完全依赖于主键，不能仅依赖主键的一部分</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="【五】第三范式（3NF）">【五】第三范式（3NF）</h2>
<h3 id="【1】什么是第三范式">【1】什么是第三范式</h3>
<ul>
<li>第三范式是满足第二范式的基础上</li>
<li>第三范式要求表中每一列数据不能与主键以外的字段有直接联系
<ul>
<li>表中的非主键列必须和主键直接相关而不能间接相关</li>
<li>非主键列之间不能相关依赖，不存在传递依赖</li>
</ul>
</li>
</ul>
<h3 id="【2】案例（第三范式）">【2】案例（第三范式）</h3>
<h4 id="（1）基于第二范式的基表">（1）基于第二范式的基表</h4>
```sql
+------------+--------+------+--------+--------------+--------------+
| student_id | name   | sex  | height | department   | dean         |
+------------+--------+------+--------+--------------+--------------+
|          1 | 蚩梦   | 男   | 185cm  | 计算机系     | 竹子老大     |
|          2 | 萌萌   | 女   | 170cm  | 金融系       | 熊猫老大     |
+------------+--------+------+--------+--------------+--------------+
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#### (2)第三范式进行优化</span><br><span class="line"></span><br><span class="line">- department : 部门</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```sql</span><br><span class="line">+---------------+-----------------+-----------------+</span><br><span class="line">| department_id | department_name | department_dean |</span><br><span class="line">+---------------+-----------------+-----------------+</span><br><span class="line">|             1 | 计算机系        | 竹子老大        |</span><br><span class="line">|             2 | 金融系          | 熊猫老大        |</span><br><span class="line">+---------------+-----------------+-----------------+</span><br></pre></td></tr></table></figure>

<ul>
<li>student：学生</li>
</ul>
```sql
+------------+--------+------+--------+---------------+
| student_id | name   | sex  | height | department_id |
+------------+--------+------+--------+---------------+
|          1 | 蚩梦   | 男   | 185cm  |             1 |
|          2 | 萌萌   | 女   | 170cm  |             2 |
+------------+--------+------+--------+---------------+
```

<ul>
<li>
<p>小结：</p>
</li>
<li>
<p>经过上述优化后，我们又将学生表拆成了 学生表 和 院系表 。</p>
</li>
<li>
<ul>
<li>学生表只存储一个院系对应的 ID</li>
<li>院系表存储院系相关的数据</li>
</ul>
</li>
<li>
<p>通过以上优化，我们可以发现</p>
</li>
<li>
<ul>
<li>学生表中的每个非主键字段与其他非主键字段之间都是相互独立的</li>
<li>彼此之间不存在任何依赖关系</li>
<li>所有的字段都依赖于主键</li>
</ul>
</li>
</ul>
<h3 id="【3】如果不调整表结构会如何？">【3】如果不调整表结构会如何？</h3>
<ul>
<li>
<p>如果不调整上述结构，那么我们在操作数据表的时候就会发生如下问题</p>
</li>
<li>
<ul>
<li>当一个院系院长换人后，需要修改学生信息表中的每一条数据</li>
<li>当一个院长离职后，需要删除院长的相关数据，包括学生表中的相关数据</li>
</ul>
</li>
<li>
<p>由此，会引发很多意料之外的错误和数据异常，让整张表较难维护</p>
</li>
</ul>
<h3 id="【4】小结">【4】小结</h3>
<ul>
<li>
<p>第三范式，我们通常也叫 3NF</p>
</li>
<li>
<ul>
<li>第三范式(3NF)是在第二范式(2NF)的基础上建立起来得</li>
<li>满足第三范式(3NF)必须先满足第二范式(2NF)</li>
</ul>
</li>
<li>
<p>第一范式要求我们必须遵守原子性</p>
</li>
<li>
<p>第二范式要求表中的所有列，其数据依赖于主键</p>
</li>
<li>
<ul>
<li>即一张表只存储同一类型的数据，不能有任何一列数据与主键没有关系</li>
</ul>
</li>
<li>
<ul>
<li>
<ul>
<li>如果表是单主键，那么主键以外的列必须完全依赖于主键，其它列需要跟主键有关系</li>
<li>如果表是复合主键，那么主键以外的列必须完全依赖于主键，不能仅依赖主键的一部分</li>
</ul>
</li>
</ul>
</li>
<li>
<p>第三范式要求表中每一列数据不能与主键之外的字段有直接关系</p>
</li>
<li>
<ul>
<li>表中的非主键列必须和主键直接相关而不能间接相关</li>
<li>非主键列之间不能相关依赖，不存在传递依赖</li>
</ul>
</li>
</ul>
<h2 id="【六】数据库三范式总结">【六】数据库三范式总结</h2>
<ul>
<li>
<p>三范式直观阐述，总结如下：</p>
</li>
<li>
<ul>
<li>第一范式：确保原子性，表中每一个列数据都必须是不可再分的字段。</li>
<li>第二范式：确保唯一性，每张表都只描述一种业务属性，一张表只描述一件事。</li>
<li>第三范式：确保独立性，表中除主键外，每个字段之间不存在任何依赖，都是独立的。</li>
</ul>
</li>
<li>
<p>没有按照范式设计时，会存在几个问题：</p>
</li>
<li>
<ul>
<li>整张表数据比较冗余，同一个学生信息会出现多条。</li>
<li>表结构特别臃肿，不易于操作，要新增一个学生信息时，需添加大量数据。</li>
<li>需要更新其他业务属性的数据时，比如院系院长换人了，需要修改所有学生的记录。</li>
</ul>
</li>
<li>
<p>但按照三范式将表结构拆开后</p>
</li>
<li>
<ul>
<li>假设要新增一条学生数据，就只需要插入学生相关的信息即可</li>
<li>同时如果某个院系的院长换人了，只需要修改院系表中的院长就行，学生表中的数据无需发生任何更改。</li>
</ul>
</li>
<li>
<p><strong>经过三范式的设计优化后，整个库中的所有表结构，会显得更为优雅，灵活性也会更强</strong></p>
</li>
</ul>
<p><img src="D:%5Cpycharm%5CTemporary_notes%5C%E5%9B%BE%E7%89%87%5Cc2f707a1-189a-4dfe-bd28-e4572d65f3c3.png" alt=""></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://aurora-lsk.asia/2025/10/15/Typora%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="坤">
      <meta itemprop="description" content="选择有时候比努力更重要，但是你不努力，选择就只是空谈">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="坤博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/10/15/Typora%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/" class="post-title-link" itemprop="url">Typora安装过程</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-10-15 11:34:56 / 修改时间：11:52:37" itemprop="dateCreated datePublished" datetime="2025-10-15T11:34:56+08:00">2025-10-15</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Blog/" itemprop="url" rel="index"><span itemprop="name">Blog</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1>【一】TYPORA安装过程</h1>
<h2 id="【1】官网">【1】官网</h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://typoraio.cn/">Typora 官方中文站 (typoraio.cn)</a></li>
</ul>
<h2 id="【2】-介绍">【2】  介绍</h2>
<ul>
<li>官方下载需要钱</li>
<li>89元</li>
</ul>
<p>![屏幕截图 2024-03-25 181319](C:\Users\86177\Pictures\Screenshots\屏幕截图 2024-03-25 181319.png)</p>
<h2 id="【3】破解">【3】破解</h2>
<h5 id="（1）搜索个平台">（1）搜索个平台</h5>
<h5 id="（2）直接用">（2）直接用</h5>
<ul>
<li>下载软件到本地</li>
<li>文件夹替换</li>
<li>C:\Program Files\Typora\resources中替换app.asar文件</li>
</ul>
<p><img src="C:%5CUsers%5C86177%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240325184633391.png" alt="image-20240325184633391"></p>
<ul>
<li>输入激活码输入</li>
</ul>
<p><img src="C:%5CUsers%5C86177%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240325184720007.png" alt="image-20240325184720007"></p>
<ul>
<li>激活成功</li>
</ul>
<p><img src="C:%5CUsers%5C86177%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240325195400670.png" alt="image-20240325195400670"></p>
<h1>【二】博客园上传笔记</h1>
<h2 id="【1】博客园网址">【1】博客园网址</h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/">https://www.cnblogs.com/</a></li>
</ul>
<h2 id="【2】进后台">【2】进后台</h2>
<p><img src="C:%5CUsers%5C86177%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240325200123975.png" alt="image-20240325200123975"></p>
<h2 id="【3】图片处理">【3】图片处理</h2>
<ul>
<li>
<p>手动拖拽</p>
</li>
<li>
<p>打开自己发送的博客园，点击编辑，把图片地址删除</p>
</li>
</ul>
<p><img src="C:%5CUsers%5C86177%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240325201521624.png" alt="image-20240325201521624"></p>
<ul>
<li>把文件夹里原来的原图片拖拽在里面就行</li>
<li>提交保存即可</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://aurora-lsk.asia/2025/10/15/Scrapy%E6%A1%86%E6%9E%B6%E4%B9%8B%E9%9B%86%E6%88%90Selenium%E6%A1%86%E6%9E%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="坤">
      <meta itemprop="description" content="选择有时候比努力更重要，但是你不努力，选择就只是空谈">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="坤博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/10/15/Scrapy%E6%A1%86%E6%9E%B6%E4%B9%8B%E9%9B%86%E6%88%90Selenium%E6%A1%86%E6%9E%B6/" class="post-title-link" itemprop="url">Scrapy框架之集成Selenium框架</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-10-15 11:34:56 / 修改时间：16:15:50" itemprop="dateCreated datePublished" datetime="2025-10-15T11:34:56+08:00">2025-10-15</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Blog/" itemprop="url" rel="index"><span itemprop="name">Blog</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1>Scrapy框架之集成Selenium框架</h1>
<ul>
<li>scrapy中集成selenium：解析使用的是selenium拿回来的页面</li>
</ul>
<h2 id="【一】前言">【一】前言</h2>
<ul>
<li>
<p>使用scrapy默认下载器</p>
</li>
<li>
<ul>
<li>类似于requests模块发送请求，不能执行js，有的页面拿回来数据不完整</li>
</ul>
</li>
<li>
<p>想在scrapy中集成selenium</p>
</li>
<li>
<ul>
<li>获取数据更完整，获取完后，自己组装成 Response对象</li>
<li>就会进爬虫解析，现在<strong>解析的是使用selenium拿回来的页面</strong>，数据更完整</li>
</ul>
</li>
</ul>
<h2 id="【二】大概步骤">【二】大概步骤</h2>
<h3 id="【1】在爬虫类里面写浏览器对象">【1】在爬虫类里面写浏览器对象</h3>
```python
from selenium.webdriver import Chrome
from selenium.webdriver.chrome.service import Service
import scrapy
import os

# 指定chromedriver.exe有效的路径
base_url = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
driver_path = os.path.join(base_url, 'chromedriver.exe')

class BlogSpider(scrapy.Spider):
    name = "blog"
    allowed_domains = ["www.cnblogs.com"]
    start_urls = ["https://www.cnblogs.com"]

    # 首先声明驱动的位置
    service = Service(executable_path=driver_path)
    # 创建浏览器的对象
    browser = Chrome(service=service)
    # 隐士等待
    browser.implicitly_wait(10)
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 【2】在中间间里面处理</span><br><span class="line"></span><br><span class="line">- 下载中间件</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```python</span><br><span class="line"># 拦截请求的所有对象</span><br><span class="line">    # 参数：request就是拦截到的请求对象，spider爬虫文件中爬虫类实例化的对象</span><br><span class="line">    # spider参数的作用可以实现类和中间类的数据交互</span><br><span class="line">    def process_request(self, request, spider):</span><br><span class="line">        # print(request.url)</span><br><span class="line">        # https://www.cnblogs.com</span><br><span class="line">        # 提取当前的url，找到含有&quot;/sitehome/p&quot;的地址</span><br><span class="line">        # 利用自己的selenium 访问并拿到源码交给Response</span><br><span class="line">        if &quot;/sitehome/p&quot; in request.url:</span><br><span class="line">            # 调用自己的selenium对象进行页面的抓取</span><br><span class="line">            spider.browser.get(request.url)</span><br><span class="line">            # 获取页面的响应源码</span><br><span class="line">            body = spider.browser.page_source</span><br><span class="line">            # 将页面源码转换为scrapy的response对象</span><br><span class="line">            # 引入一个方法</span><br><span class="line">            from scrapy.http.response.html import HtmlResponse</span><br><span class="line">            return HtmlResponse(</span><br><span class="line">                url=request.url,</span><br><span class="line">                body=bytes(body, encoding=&#x27;utf-8&#x27;)</span><br><span class="line">            )</span><br><span class="line">        else:</span><br><span class="line">            return None</span><br></pre></td></tr></table></figure>

<h3 id="【3】再配置文件中开启中间件">【3】再配置文件中开启中间件</h3>
```python
# 是否启用下载器中间件
DOWNLOADER_MIDDLEWARES = {
   "SpiderNews.middlewares.SpiderNewsDownloaderMiddleware": 543,
}
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line">&#123;% endraw %&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 【三】总的步骤</span><br><span class="line"></span><br><span class="line">- 爬虫程序</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;% raw %&#125;```python</span><br><span class="line">import scrapy</span><br><span class="line">from scrapy import Request</span><br><span class="line">from selenium.webdriver import Chrome</span><br><span class="line">from selenium.webdriver.chrome.service import Service</span><br><span class="line">from SpiderNews.items import BoKeYuanItem</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">base_url = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))</span><br><span class="line">driver_path = os.path.join(base_url, &#x27;chromedriver.exe&#x27;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class BlogSpider(scrapy.Spider):</span><br><span class="line">    name = &quot;blog&quot;</span><br><span class="line">    allowed_domains = [&quot;www.cnblogs.com&quot;]</span><br><span class="line">    start_urls = [&quot;https://www.cnblogs.com&quot;]</span><br><span class="line"></span><br><span class="line">    # 首先声明驱动的位置</span><br><span class="line">    service = Service(executable_path=driver_path)</span><br><span class="line">    # 创建浏览器的对象</span><br><span class="line">    browser = Chrome(service=service)</span><br><span class="line">    # 隐士等待</span><br><span class="line">    browser.implicitly_wait(10)</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        # 用Xpath语法爬取数据</span><br><span class="line">        article_list = response.xpath(&#x27;//*[@id=&quot;post_list&quot;]/article&#x27;)</span><br><span class="line">        # print(article_list)</span><br><span class="line">        for article in article_list:</span><br><span class="line">            # 创建一个管道类对象</span><br><span class="line">            item = BoKeYuanItem()</span><br><span class="line">            # 拿到头像</span><br><span class="line">            # //*[@id=&quot;post_list&quot;]/article[1]/section/div/p/a/img</span><br><span class="line">            head_img_url = article.xpath(&#x27;./section/div/p/a[1]/img/@src&#x27;).extract_first()</span><br><span class="line">            # 文章的作者</span><br><span class="line">            # //*[@id=&quot;post_list&quot;]/article[1]/section/footer/a[1]/span</span><br><span class="line">            article_author = article.xpath(&#x27;./section/footer/a[1]/span/text()&#x27;).extract_first()</span><br><span class="line">            # 文章标题</span><br><span class="line">            # //*[@id=&quot;post_list&quot;]/article[1]/section/div/a</span><br><span class="line">            article_title = article.xpath(&#x27;./section/div/a/text()&#x27;).extract_first().strip()</span><br><span class="line">            # 创建一个详情链接</span><br><span class="line">            # //*[@id=&quot;post_list&quot;]/article[1]/section/div/a</span><br><span class="line">            article_link = article.xpath(&#x27;./section/div/a/@href&#x27;).extract_first()</span><br><span class="line">            # 拿到文章内容</span><br><span class="line">            # //*[@id=&quot;post_list&quot;]/article[2]/section/div/p/text()</span><br><span class="line">            # //*[@id=&quot;post_list&quot;]/article[1]/section/div/p/text()</span><br><span class="line">            # /html/body/div/div[3]/div/div[2]/div[1]/div[4]/article[3]/section/div/p/text()</span><br><span class="line">            article_desc_list = article.xpath(&#x27;./section/div/p/text()&#x27;).extract()</span><br><span class="line">            article_desc = &#x27;&#x27;</span><br><span class="line">            for article_desc in article_desc_list:</span><br><span class="line">                if not article_desc:</span><br><span class="line">                    pass</span><br><span class="line">                else:</span><br><span class="line">                    article_desc = article_desc.strip()</span><br><span class="line">            # 文章更新时间</span><br><span class="line">            # //*[@id=&quot;post_list&quot;]/article[1]/section/footer/span[1]/span</span><br><span class="line">            article_update_time = article.xpath(&#x27;./section/footer/span[1]/span/text()&#x27;).extract_first().strip()</span><br><span class="line">            # print(article_update_time)</span><br><span class="line">            # itme是一个字典--&gt;用字典方便，可以update()更新数据，更新的时候，更新字段要和管道类里面的字段一摸一样</span><br><span class="line">            # print(f&quot;----&#123;article_desc&#125;---&quot;)</span><br><span class="line">            item.update(&#123;</span><br><span class="line">                &quot;head_img_url&quot;: head_img_url,</span><br><span class="line">                &quot;article_author&quot;: article_author,</span><br><span class="line">                &quot;article_title&quot;: article_title,</span><br><span class="line">                &quot;article_link&quot;: article_link,</span><br><span class="line">                &quot;article_desc&quot;: article_desc,</span><br><span class="line">                &quot;article_update_time&quot;: article_update_time</span><br><span class="line">            &#125;)</span><br><span class="line">            # 将itme对象返回出去</span><br><span class="line">            # return 会结束整个程序，不用它</span><br><span class="line">            # 我们用yield，yield可以保存item的状态，不会终止程序的执行</span><br><span class="line">            yield Request(</span><br><span class="line">                url=article_link,</span><br><span class="line">                callback=self.detail_parse,</span><br><span class="line">                meta=&#123;&quot;item&quot;: item&#125;</span><br><span class="line">            )</span><br><span class="line">        # 获取下一页的链接地址</span><br><span class="line">        # 这里的流程就是，for把所有的article遍历出来以后，就会走这里，走到这里就代表该爬下一页的数据了</span><br><span class="line">        # //*[@id=&quot;paging_block&quot;]/div/a[5]</span><br><span class="line">        next_url = &#x27;https://www.cnblogs.com&#x27; + response.xpath(</span><br><span class="line">            &#x27;//*[@id=&quot;paging_block&quot;]/div/a[last()]/@href&#x27;).extract_first()</span><br><span class="line">        yield Request(</span><br><span class="line">            url=next_url,</span><br><span class="line">            callback=self.parse</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def detail_parse(self, response):</span><br><span class="line">        # 获取到传入的item对象</span><br><span class="line">        item = response.meta.get(&#x27;item&#x27;)</span><br><span class="line">        # 解析文章详情</span><br><span class="line">        content = str(response.xpath(&#x27;//*[@id=&quot;topics&quot;]&#x27;).extract_first())</span><br><span class="line">        # 继续向 item 对象中添加文章详情内容</span><br><span class="line">        item[&#x27;article_content&#x27;] = content</span><br><span class="line">        # 将完整的信息返回</span><br><span class="line">        yield item</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>中间件</li>
</ul>
```python
# 下载中间件
class SpiderNewsDownloaderMiddleware:
# 拦截请求的所有对象
    # 参数：request就是拦截到的请求对象，spider爬虫文件中爬虫类实例化的对象
    # spider参数的作用可以实现类和中间类的数据交互
    def process_request(self, request, spider):
        # print(request.url)
        # https://www.cnblogs.com
        # 提取当前的url，找到含有"/sitehome/p"的地址
        # 利用自己的selenium 访问并拿到源码交给Response
        if "/sitehome/p" in request.url:
            # 调用自己的selenium对象进行页面的抓取
            spider.browser.get(request.url)
            # 获取页面的响应源码
            body = spider.browser.page_source
            # 将页面源码转换为scrapy的response对象
            # 引入一个方法
            from scrapy.http.response.html import HtmlResponse
            return HtmlResponse(
                url=request.url,
                body=bytes(body, encoding='utf-8')
            )
        else:
            return None
```


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://aurora-lsk.asia/2025/10/15/Xpath---JD%E6%A1%88%E4%BE%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="坤">
      <meta itemprop="description" content="选择有时候比努力更重要，但是你不努力，选择就只是空谈">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="坤博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/10/15/Xpath---JD%E6%A1%88%E4%BE%8B/" class="post-title-link" itemprop="url">Xpath---JD案例</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-10-15 11:34:56 / 修改时间：16:15:50" itemprop="dateCreated datePublished" datetime="2025-10-15T11:34:56+08:00">2025-10-15</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Blog/" itemprop="url" rel="index"><span itemprop="name">Blog</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1>Xpath—JD案例</h1>
```python
# Current username：爬虫 
# current date：2024/7/18
# current time ：20:24

import requests
from fake_useragent import UserAgent
from lxml import etree


class SpiderJD:
    def __init__(self):
        self.target_url = 'https://search.jd.com/Search'
        self.headers = {
            'User-Agent': UserAgent().random,
            'cookie': 'unpl=JF8EAK5nNSttCElSV0gFT0FETgpUWw4PSx8HbzVVVFtRSQNQGQdLEBZ7XlVdWBRKER9vbhRUVVNPUA4aASsSEXteXVdZDEsWC2tXVgQFDQ8VXURJQlZAFDNVCV9dSRZRZjJWBFtdT1xWSAYYRRMfDlAKDlhCR1FpMjVkXlh7VAQrCx0aE0pZUVpVOEonBF9XNVNfX0pSACsDKxMgCQkIXVgAQxADIm4DXF5ZT1EBEzIaIhM; __jdv=76161171|baidu-pinzhuan|t_288551095_baidupinzhuan|cpc|0f3d30c8dba7459bb52f2eb5eba8ac7d_0_a37cb6ebe4f14b61951ca1783fd34a37|1721303702650; __jdu=879205459; areaId=2; ipLoc-djd=2-2830-0-0; PCSYCityID=CN_310000_310100_0; shshshfpa=4478e6fc-66dd-0aa5-8b60-231dd4b08b7b-1721303703; shshshfpx=4478e6fc-66dd-0aa5-8b60-231dd4b08b7b-1721303703; mt_xid=V2_52007VwoUWl5ZVl8bQSlaAWFTRQJbCk5fTx4fQABkAEZODV5aDwNKTAhSZVYRUlVZUA0vShhfAHsCFE5dUUNaF0IdWA5mBiJSbVhiWRlAH1kHZwQVW1xoVl4cSw%3D%3D; _pst=jd_4a91e650cd9db; unick=jd_397vk80cnvgo8s; pin=jd_4a91e650cd9db; thor=7B313C99DB275AE5C764C0B60003C437FC74A96B6B69EDD9208823C5605C9BA18CA7B18A1AAEFAEA8DE68FE1212FE6F9F98A30F6BE8CA6CA8A06D8EC7D63C0F5800574631A2FADE4A4B11E8430FE806A5E4EA4F8744D8578A71EA9AB91424FB938CBECAFF201BED3936D408C1E9123DF8AF4DD208CAF142FFE79C4B2FFD4B5C18F0D1963337C12CDF2917CEFFA7D8C203FD43BC7014318CE2C697AC7C6F64D9B; flash=2_8JWjGuwDPim1IDMs4fzpIr5eZvfMSFHx-Yyrdm69TtYdJC7IJuTBs0H51Sm7j0PViQKXgI8bJ-5YagIdtxi_yoU3fg5KVdCglVGY9fxWxRPjWE6HK56Urzb5VE2kK-yTE0O37pIBhhdAaSaZnE6PzCOZSgY8LzKFWxy8W9UGYt5*; _tp=SACEmZU4OohYaEFpbqf7X4%2FGM7qJetbpBri8Wb%2Bveq4%3D; pinId=kZyY4NkPNVHcLtr2Y91ugbV9-x-f3wj7; jsavif=1; jsavif=1; __jda=143920055.879205459.1721303702.1721303702.1721303703.1; __jdc=143920055; rkv=1.0; avif=1; xapieid=jdd03N5XF4VIWT7TIO6XK2DZLWO3W3VFEJZCITSMME7PGOPLOL3YQNL6YYPNT7SXH57RVVBJWCZR7GN2SZMM2J52YA7NNZAAAAAMQYXHH6VIAAAAACZAYI55Q2IVWKUX; qrsc=3; __jdb=143920055.12.879205459|1.1721303703; 3AB9D23F7A4B3CSS=jdd03N5XF4VIWT7TIO6XK2DZLWO3W3VFEJZCITSMME7PGOPLOL3YQNL6YYPNT7SXH57RVVBJWCZR7GN2SZMM2J52YA7NNZAAAAAMQYXJXJOYAAAAADYA6DZV5FBWOIYX; _gia_d=1; shshshfpb=BApXcouDbxvVAjkjslJrkETmpSmpvdjqhBmNxMCwX9xJ1MiU5hIC2; 3AB9D23F7A4B3C9B=N5XF4VIWT7TIO6XK2DZLWO3W3VFEJZCITSMME7PGOPLOL3YQNL6YYPNT7SXH57RVVBJWCZR7GN2SZMM2J52YA7NNZA'
        }

    # 住区京东零食的html
    def spider_page_tree(self):
        # 路径的参数
        # params = {
        #     "keyword": '零食'
        # }
        # 拼接路径
        # response = requests.get(self.target_url, headers=self.headers, params=params)
        #
        # page_text = response.text
        # 将得到的源码信息保存起来
        # self.save(data=page_text)
        # 查看原始的请求地址，判断是不是想要的数据
        # print(response.request.url)
        # 保存好以后就不用上面的了，直接读
        data = self.read()
        tree = etree.HTML(data)
        return tree

    # 将得到的数据HTML,存起来
    def save(self,data):
        with open('jd.html', 'w', encoding='utf8') as fp:
            fp.write(data)

    # 读取HTML页面
    def read(self):
        with open('jd.html', 'r', encoding='utf8') as fp:
            data = fp.read()
        return data

    # 解析源码
    def parse_good_data(self):
        tree = self.spider_page_tree()
        # 拿到零食的li标签
        li_list = tree.xpath('//*[@id="J_goodsList"]/ul/li')
        # 拿到了所有的li标签
        # print(li_list)
        good_data = {}
        for li in li_list:
            # 拿到了所有的价格
            # //*[@id="J_goodsList"]/ul/li[1]/div/div[2]/strong/i
            # print(li.xpath('./div/div[2]/strong/i/text()')[0])
            price = li.xpath('./div/div[2]/strong/i/text()')[0]

            # 那所有的商品信息
            # //*[@id="J_goodsList"]/ul/li[1]/div/div[3]/a/em
            # print(li.xpath('./div/div[3]/a/em/text()')[0])
            desc = li.xpath('./div/div[3]/a/em/text()')[0]

            # 获得店名
            store_name = li.xpath('./div/div[5]/span/a/text()')[0]
            # print(store_name)

            # 营业模式
            trade_mode = li.xpath('//*[@id="J_pro_100047511237"]/i/text()')[0]
            # print(trade_mode)
            good_data[store_name] = {
                "desc": desc.strip(),
                "price": price,
                "trade_mode": trade_mode
            }
            print(good_data)

if __name__ == '__main__':
    s = SpiderJD()
    s.parse_good_data()

```


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://aurora-lsk.asia/2025/10/15/pycharm%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="坤">
      <meta itemprop="description" content="选择有时候比努力更重要，但是你不努力，选择就只是空谈">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="坤博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/10/15/pycharm%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/" class="post-title-link" itemprop="url">pycharm安装过程</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2025-10-15 11:34:56 / 修改时间：11:52:37" itemprop="dateCreated datePublished" datetime="2025-10-15T11:34:56+08:00">2025-10-15</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Blog/" itemprop="url" rel="index"><span itemprop="name">Blog</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1>【一】pycharm安装过程</h1>
<h3 id="【1】官网地址">【1】官网地址</h3>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.jetbrains.com.cn/">https://www.jetbrains.com.cn/</a></li>
</ul>
<h2 id="【2】下载pycharm">【2】下载pycharm</h2>
<ul>
<li>选择pycharm软件</li>
</ul>
<p><img src="C:%5CUsers%5C86177%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240326154803956.png" alt="image-20240326154803956"></p>
<ul>
<li>点击下载</li>
</ul>
<p><img src="C:%5CUsers%5C86177%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240326154832364.png" alt="image-20240326154832364"></p>
<ul>
<li>下载安装包</li>
<li>
<img src="C:\Users\86177\AppData\Roaming\Typora\typora-user-images\image-20240326154918653.png" alt="image-20240326154918653" style="zoom:25%;" />
</li>
</ul>
<h2 id="【3】安装pycharm软件">【3】安装pycharm软件</h2>
<ul>
<li>
<p>双击安装包</p>
</li>
<li>
<p>安装路径不要出现中文</p>
</li>
<li>
<p><img src="C:%5CUsers%5C86177%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240326155502913.png" alt="image-20240326155502913"></p>
</li>
<li>
<p>选择朋友pycharm配置</p>
</li>
</ul>
<p><img src="C:%5CUsers%5C86177%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240326155611121.png" alt="image-20240326155611121"></p>
<ul>
<li>安装jetbrains</li>
</ul>
<p><img src="C:%5CUsers%5C86177%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240326155817679.png" alt="image-20240326155817679"></p>
<ul>
<li>安装完成</li>
</ul>
<p><img src="C:%5CUsers%5C86177%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240326155849271.png" alt="image-20240326155849271"></p>
<ul>
<li>提示激活码</li>
</ul>
<p><img src="C:%5CUsers%5C86177%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240326155921408.png" alt="image-20240326155921408"></p>
<h2 id="【4】激活pycharm">【4】激活pycharm</h2>
<h3 id="（1）脚本破解版">（1）脚本破解版</h3>
<ul>
<li>
<p>激活码</p>
</li>
<li>
<p>参考网址</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://blog.junxu666.top/p/46415.html">https://blog.junxu666.top/p/46415.html</a></li>
</ul>
</li>
<li>
<p>重新打开 Pycharm 后，打开网址，复制里面的激活码</p>
</li>
<li>
<p>粘贴到输入框内，点击 <code>Activate</code> 按钮，就激活成功了</p>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="http://zhaochunze.dream521.site/202311151836249.jpeg"><img src="http://zhaochunze.dream521.site/202311151836249.jpeg" alt="输入 Pycharm 破解激活码"></a></p>
<h1>【二】使用pycharm软件运行python软件</h1>
<h2 id="【1】创建项目">【1】创建项目</h2>
<ul>
<li>名称用英文</li>
</ul>
<p><img src="C:%5CUsers%5C86177%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240326162032990.png" alt="image-20240326162032990"></p>
<ul>
<li>点击创建python文件</li>
</ul>
<p><img src="C:%5CUsers%5C86177%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240326163143939.png" alt="image-20240326163143939"></p>
<ul>
<li>输入名称</li>
</ul>
<p><img src="C:%5CUsers%5C86177%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240326163201913.png" alt="image-20240326163201913"></p>
<ul>
<li>输入python代码</li>
</ul>
<p><img src="C:%5CUsers%5C86177%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240326163406114.png" alt="image-20240326163406114"></p>
<ul>
<li>点击运行python代码</li>
</ul>
<p><img src="C:%5CUsers%5C86177%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240326163458500.png" alt="image-20240326163458500"></p>
<ul>
<li>运行效果</li>
</ul>
<p><img src="C:%5CUsers%5C86177%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20240326163303908.png" alt="image-20240326163303908"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/20/">20</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">坤</p>
  <div class="site-description" itemprop="description">选择有时候比努力更重要，但是你不努力，选择就只是空谈</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">194</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">坤</span>
</div>
  <div class="powered-by">由 <a href="https://github.com/lsk-0912" class="theme-link" rel="noopener" target="_blank">lsk-0912</a> & <a href="https://github.com/lsk-0912" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
